{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "702bf3b9",
   "metadata": {},
   "source": [
    "# 1. Description of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881cbdaa",
   "metadata": {},
   "source": [
    "Following Datasets are used for this research.\n",
    "\n",
    "1. Total Electricity Demand NSW\n",
    "2. Air Temperature NSW\n",
    "3. NSW Calendar\n",
    "4. Total Forecast Demand NSW\n",
    "\n",
    "\n",
    "### **1. Total Electricy Demand NSW**\n",
    "\n",
    "Total Electricity Demand in 30 min increments. This data is sourced from the Market Management System database, which is published by the market operator from the National Electricity Market (NEM) system. \n",
    "\n",
    "<table style='float:left'>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "        <td>\n",
    "        <p><strong>Row Count</strong></p>\n",
    "        </td>\n",
    "        <td>\n",
    "        <p><strong>File Size (Approx)</strong></p>\n",
    "        </td>\n",
    "        <td>\n",
    "        <p><strong>File Format</strong></p>\n",
    "        </td>\n",
    "        <td>\n",
    "        <p><strong>File Name</strong></p>\n",
    "        </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "        <p>196513</p>\n",
    "        </td>\n",
    "        <td>\n",
    "        <p>5.6 MB</p>\n",
    "        </td>\n",
    "        <td>\n",
    "        <p>CSV</p>\n",
    "        </td>\n",
    "        <td>\n",
    "        <p>totaldemand_nsw.csv</p>\n",
    "        </td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381096b5",
   "metadata": {},
   "source": [
    "<table style='float:left'>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>\n",
    "<p><strong>Attributes</strong></p>\n",
    "</td>\n",
    "<td width=\"284\">\n",
    "<p><strong>Description</strong></p>\n",
    "</td>\n",
    "<td width=\"138\">\n",
    "<p><strong>Attribute Characteristics</strong></p>\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "<p>DATETIME</p>\n",
    "</td>\n",
    "<td width=\"284\">\n",
    "<p>Date and time interval of each observation. Format (dd/mm/yyyy hh:mm)</p>\n",
    "</td>\n",
    "<td width=\"138\">\n",
    "<p>Timestamp</p>\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "<p>TOTALDEMAND</p>\n",
    "</td>\n",
    "<td width=\"284\">\n",
    "<p>Total demand in MW</p>\n",
    "</td>\n",
    "<td width=\"138\">\n",
    "<p>Numeric</p>\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "<p>REGIONID</p>\n",
    "</td>\n",
    "<td width=\"284\">\n",
    "<p>Region Identifier (i.e. NSW1)</p>\n",
    "</td>\n",
    "<td width=\"138\">\n",
    "<p>String.</p>\n",
    "<p>Categorical</p>\n",
    "</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ff8aa5",
   "metadata": {},
   "source": [
    "### **2. Air Temperature NSW**\n",
    "\n",
    "Air temperature in NSW (as measured from the Bankstown Airport weather station). This data is sourced from the Australian Data Archive for Meteorology. Note: Unlike the total demand and forecast demand, the time interval between each observation may not be constant (i.e. half-hourly data). As noted in the literature review, temperature is a key driver of demand. Therefore, this dataset is critically important for the research question\n",
    "\n",
    "<table style='float:left'>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>\n",
    "<p><strong>Row Count</strong></p>\n",
    "</td>\n",
    "<td>\n",
    "<p><strong>File Size (Approx)</strong></p>\n",
    "</td>\n",
    "<td>\n",
    "<p><strong>File Format</strong></p>\n",
    "</td>\n",
    "<td>\n",
    "<p><strong>File Name</strong></p>\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "<p>220326</p>\n",
    "</td>\n",
    "<td>\n",
    "<p>6.7 MB</p>\n",
    "</td>\n",
    "<td>\n",
    "<p>CSV</p>\n",
    "</td>\n",
    "<td>\n",
    "<p>temperature_nsw.csv</p>\n",
    "</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6369a7cb",
   "metadata": {},
   "source": [
    "<table style='float:left'>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>\n",
    "<p><strong>Attributes</strong></p>\n",
    "</td>\n",
    "<td width=\"288\">\n",
    "<p><strong>Description</strong></p>\n",
    "</td>\n",
    "<td width=\"138\">\n",
    "<p><strong>Attribute Characteristics</strong></p>\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "<p>DATETIME</p>\n",
    "</td>\n",
    "<td width=\"288\">\n",
    "<p>Date and time interval of each observation. Format (dd/mm/yyyy hh:mm)</p>\n",
    "</td>\n",
    "<td width=\"138\">\n",
    "<p>Timestamp</p>\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "<p>TEMPERATURE</p>\n",
    "</td>\n",
    "<td width=\"288\">\n",
    "<p>Air temperature (&deg;C)</p>\n",
    "</td>\n",
    "<td width=\"138\">\n",
    "<p>Numeric</p>\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "<p>LOCATION</p>\n",
    "</td>\n",
    "<td width=\"288\">\n",
    "<p>Location of a weather station (i.e., Bankstown weather station)</p>\n",
    "</td>\n",
    "<td width=\"138\">\n",
    "<p>String</p>\n",
    "<p>Categorical</p>\n",
    "</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "<p>&nbsp;</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da508f13",
   "metadata": {},
   "source": [
    "### **3. NSW Calendar**\n",
    "\n",
    "Create NSW Calendar to include holidays, seasons, weekends.\n",
    "\n",
    "<table style='float:left'>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>\n",
    "<p><strong>Attributes</strong></p>\n",
    "</td>\n",
    "<td width=\"288\">\n",
    "<p><strong>Description</strong></p>\n",
    "</td>\n",
    "<td width=\"138\">\n",
    "<p><strong>Attribute Characteristics</strong></p>\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "<p>DATETIME</p>\n",
    "</td>\n",
    "<td width=\"288\">\n",
    "<p>Date and time interval of each observation. Generated through Python library</p>\n",
    "</td>\n",
    "<td width=\"138\">\n",
    "<p>Timestamp</p>\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "<p>HOLIDAY</p>\n",
    "</td>\n",
    "<td width=\"288\">\n",
    "<p>Marked 1 if public holiday in NSW, otherwise 0. Generated using 'holidays' Python library</p>\n",
    "<p>Sourced from the python library https://pypi.org/project/holidays/</p>\n",
    "</td>\n",
    "<td width=\"138\">\n",
    "<p>Numeric</p>\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "<p>SUMMER</p>\n",
    "</td>\n",
    "<td width=\"288\">\n",
    "<p>Marked 1 if the month is in Summer season, else 0.</p>\n",
    "<p>Use one hot encoding</p>\n",
    "</td>\n",
    "<td width=\"138\">\n",
    "<p>Numeric</p>\n",
    "</td>\n",
    "</tr>\n",
    "    \n",
    "<tr>\n",
    "<td>\n",
    "<p>AUTUMN</p>\n",
    "</td>\n",
    "<td width=\"288\">\n",
    "<p>Marked 1 if the month is in Autumn season, else 0</p>\n",
    "<p>Use one hot encoding</p>    \n",
    "</td>\n",
    "<td width=\"138\">\n",
    "<p>Numeric</p>\n",
    "</td>\n",
    "</tr>\n",
    "\n",
    "    \n",
    "<tr>\n",
    "<td>\n",
    "<p>WINTER</p>\n",
    "</td>\n",
    "<td width=\"288\">\n",
    "<p>Marked 1 if the month is in Winter season, else 0</p>\n",
    "<p>Use one hot encoding</p>\n",
    "</td>\n",
    "<td width=\"138\">\n",
    "<p>Numeric</p>\n",
    "</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>\n",
    "<p>SPRING</p>\n",
    "</td>\n",
    "<td width=\"288\">\n",
    "<p>Marked 1 if the month is in Spring season, else 0</p>\n",
    "<p>Use one hot encoding</p>\n",
    "</td>\n",
    "<td width=\"138\">\n",
    "<p>Numeric</p>\n",
    "</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>\n",
    "<p>WEEKDAY</p>\n",
    "</td>\n",
    "<td width=\"288\">\n",
    "<p>Marked 1 if day of week is between Monday to Friday, else 0</p>\n",
    "</td>\n",
    "<td width=\"138\">\n",
    "<p>Numeric</p>\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "<p>DAYOFWEEK</p>\n",
    "</td>\n",
    "<td width=\"288\">\n",
    "<p>Marked 1 to 7 to indicate day of week</p>\n",
    "</td>\n",
    "<td width=\"138\">\n",
    "<p>Numeric</p>\n",
    "</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>\n",
    "<p>MONTH</p>\n",
    "</td>\n",
    "<td width=\"288\">\n",
    "<p>Month of the Year</p>\n",
    "</td>\n",
    "<td width=\"138\">\n",
    "<p>Numeric</p>\n",
    "</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "<p>&nbsp;</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f7ba16",
   "metadata": {},
   "source": [
    "### **4. Total Forecast Demand NSW**\n",
    "\n",
    "Forecast demand in half-hourly increments for NSW. Data also sourced from the Market Management System database. \n",
    "This dataset would be valuable for us to validate the outcome of our model. Especially to understand the accuracy.\n",
    "\n",
    "<table style='float:left'>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>\n",
    "<p><strong>Row Count</strong></p>\n",
    "</td>\n",
    "<td>\n",
    "<p><strong>File Size (Approx)</strong></p>\n",
    "</td>\n",
    "<td>\n",
    "<p><strong>File Format</strong></p>\n",
    "</td>\n",
    "<td>\n",
    "<p><strong>File Name</strong></p>\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "<p>10906019</p>\n",
    "</td>\n",
    "<td>\n",
    "<p>722 MB</p>\n",
    "</td>\n",
    "<td>\n",
    "<p>CSV</p>\n",
    "</td>\n",
    "<td>\n",
    "<p>forecastdemand_nsw.csv</p>\n",
    "</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef6d5d9",
   "metadata": {},
   "source": [
    "<table  style='float:left'>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>\n",
    "<p><strong>Attributes</strong></p>\n",
    "</td>\n",
    "<td width=\"256\">\n",
    "<p><strong>Description</strong></p>\n",
    "</td>\n",
    "<td width=\"129\">\n",
    "<p><strong>Attribute Characteristics</strong></p>\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "<p>DATETIME</p>\n",
    "</td>\n",
    "<td width=\"256\">\n",
    "<p>Date and time interval of each observation. Format (dd/mm/yyyy hh:mm)</p>\n",
    "</td>\n",
    "<td width=\"129\">\n",
    "<p>Timestamp</p>\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "<p>FORECASTDEMAND</p>\n",
    "</td>\n",
    "<td width=\"256\">\n",
    "<p>Forecast demand in MW</p>\n",
    "</td>\n",
    "<td width=\"129\">\n",
    "<p>Numeric</p>\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "<p>REGIONID</p>\n",
    "</td>\n",
    "<td width=\"256\">\n",
    "<p>Region Identifier (i.e. NSW1)</p>\n",
    "</td>\n",
    "<td width=\"129\">\n",
    "<p>String</p>\n",
    "<p>Categorical</p>\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "<p>PREDISTPATCHSEQNO</p>\n",
    "</td>\n",
    "<td width=\"256\">\n",
    "<p>Unique identifier of predispatch run (YYYYMMDDPP). In energy generation, &ldquo;dispatch&rdquo; refers to process of sending out energy to the power grid to meet energy demand. &ldquo;Predispatch&rdquo; then is an estimated forecast of this amount.</p>\n",
    "</td>\n",
    "<td width=\"129\">\n",
    "<p>String (Identifier)</p>\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "<p>PERIODID</p>\n",
    "</td>\n",
    "<td width=\"256\">\n",
    "<p>Period count, starting from 1 for each predispatch run.</p>\n",
    "</td>\n",
    "<td width=\"129\">\n",
    "<p>Numeric (Integer)</p>\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "<p>LASTCHANGE</p>\n",
    "</td>\n",
    "<td width=\"256\">\n",
    "<p>Date time interval of each update of the observation (dd/mm/yyyy hh:mm)</p>\n",
    "</td>\n",
    "<td width=\"129\">\n",
    "<p>Timestamp</p>\n",
    "</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e5ff27",
   "metadata": {},
   "source": [
    "# 2. Pre-processing Steps\n",
    "\n",
    "### 1. Merge zip files\n",
    "\n",
    "Total Forecast demand dataset is split to two zip files. This needs to be merged prior to consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0dce6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "..\\data\\NSW\\forecastdemand_nsw.csv.zip.partaa\n",
      "\n",
      "\n",
      "\n",
      "..\\data\\NSW\\forecastdemand_nsw.csv.zip.partab\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import platform as pt\n",
    "# If OS is WINDOWS\n",
    "if pt.system() == 'Windows':\n",
    "    !type ..\\data\\NSW\\forecastdemand_nsw.csv.zip.parta* > ..\\data\\NSW\\forecastdemand_nsw.csv.zip\n",
    "else:\n",
    "# If OS is Apple/Unix based\n",
    "    !cat ..\\data\\NSW\\forecastdemand_nsw.csv.zip.parta* > ..\\data\\NSW\\forecastdemand_nsw.csv.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb86652",
   "metadata": {},
   "source": [
    "### 2. Read zip files\n",
    "\n",
    "Since all the CSV files are zipped, instead of unzipping the files, we will read the zipped file content into a dataframe for subsequent processing. This is more efficient as the code will execute across multiple Operating Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c211782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile as zp\n",
    "\n",
    "zf_td = zp.ZipFile(r'..\\data\\NSW\\totaldemand_nsw.csv.zip')\n",
    "df_td = pd.read_csv(zf_td.open('totaldemand_nsw.csv'))\n",
    "\n",
    "zf_tp = zp.ZipFile(r'..\\data\\NSW\\temperature_nsw.csv.zip')\n",
    "df_tp = pd.read_csv(zf_tp.open('temperature_nsw.csv'))\n",
    "\n",
    "zf_fd = zp.ZipFile(r'..\\data\\NSW\\forecastdemand_nsw.csv.zip')\n",
    "df_fd = pd.read_csv(zf_fd.open('forecastdemand_nsw.csv'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4754330",
   "metadata": {},
   "source": [
    "# 3. Data Cleaning\n",
    "\n",
    "### **1. Total Electricy Demand NSW**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508c7c5d",
   "metadata": {},
   "source": [
    "---\n",
    "#### Describe the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f63837d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No of rows and columns:  (196513, 3)\n",
      "\n",
      "Columns and datatypes\n",
      "DATETIME        object\n",
      "TOTALDEMAND    float64\n",
      "REGIONID        object\n",
      "dtype: object\n",
      "\n",
      "Statistics\n",
      "         TOTALDEMAND\n",
      "count  196513.000000\n",
      "mean     8113.145859\n",
      "std      1299.532774\n",
      "min      5074.630000\n",
      "25%      7150.070000\n",
      "50%      8053.230000\n",
      "75%      8958.550000\n",
      "max     14579.860000\n"
     ]
    }
   ],
   "source": [
    "# No of rows and columns\n",
    "print('\\nNo of rows and columns: ', df_td.shape)\n",
    "\n",
    "# Columns and datatypes\n",
    "print('\\nColumns and datatypes')\n",
    "print(df_td.dtypes)\n",
    "\n",
    "# Describe the data\n",
    "print('\\nStatistics')\n",
    "print(df_td.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a929172",
   "metadata": {},
   "source": [
    "---\n",
    "#### Remove unused columns\n",
    "\n",
    "As REGIONID is not useful for the research question, it is removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df3c1ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NSW1']\n"
     ]
    }
   ],
   "source": [
    "print(df_td['REGIONID'].unique())\n",
    "\n",
    "df_td = df_td.drop(['REGIONID'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce13ac5",
   "metadata": {},
   "source": [
    "---\n",
    "#### Validate Null Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9662fbf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATETIME       0\n",
       "TOTALDEMAND    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_td.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032a2a85",
   "metadata": {},
   "source": [
    "---\n",
    "#### Validate Duplicate Rows\n",
    "\n",
    "\n",
    "Check for duplicated timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34f0a3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_td.duplicated(subset=['DATETIME']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a5c01a",
   "metadata": {},
   "source": [
    "---\n",
    "#### Validate Missing Data\n",
    "\n",
    "\n",
    "a) Validate whether dates are missing between minimum date and maximum date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e67265c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Date:  2010-01-01\n",
      "Maximum Date:  2021-03-18\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Convert to DateTime datatype\n",
    "df_td['DATETIME'] = pd.to_datetime(df_td['DATETIME'], format='%d/%m/%Y %H:%M')\n",
    "df_td_val = df_td.copy()\n",
    "df_td_val['DATE'] = df_td_val['DATETIME'].dt.date\n",
    "\n",
    "# Find minimum and maximum values\n",
    "min_date = df_td_val['DATE'].min()\n",
    "max_date = df_td_val['DATE'].max()\n",
    "\n",
    "print(\"Minimum Date: \", min_date)\n",
    "print(\"Maximum Date: \", max_date)\n",
    "\n",
    "# generate all the dates in the calendar from min date to max date\n",
    "df_cal = pd.DataFrame({\"Calendar_Date\": pd.date_range(min_date, max_date)})\n",
    "\n",
    "print(pd.date_range(min_date, max_date).difference(df_td_val['DATE']).to_series().count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a34e368",
   "metadata": {},
   "source": [
    "b) Validate if demand is recorded consistently for each date.\n",
    "\n",
    "Since demand is recorded every 30mins, each day should consist of 48 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "720b9bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DATETIME  TOTALDEMAND        DATE      TIME\n",
      "196512 2021-03-18      7094.51  2021-03-18  00:00:00\n"
     ]
    }
   ],
   "source": [
    "df_td_val['TIME'] = df_td['DATETIME'].dt.time\n",
    "df_gp = df_td_val.groupby('DATE').filter(lambda x: x['TIME'].count() != 48)\n",
    "print(df_gp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a83374",
   "metadata": {},
   "source": [
    "It seems the last date has only one record. Hence this should be excluded to ensure consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19961fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_td = df_td.drop(df_td[df_td['DATETIME'] == '2021-03-18 00:00:00'].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34af8712",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### **2. Air Temperature NSW**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60948a81",
   "metadata": {},
   "source": [
    "---\n",
    "#### Describe the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6f4e25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No of rows and columns:  (220326, 3)\n",
      "\n",
      "Columns and datatypes\n",
      "LOCATION        object\n",
      "DATETIME        object\n",
      "TEMPERATURE    float64\n",
      "dtype: object\n",
      "\n",
      "Statistics:\n",
      "         TEMPERATURE\n",
      "count  220326.000000\n",
      "mean       17.418827\n",
      "std         5.849763\n",
      "min        -1.300000\n",
      "25%        13.400000\n",
      "50%        17.700000\n",
      "75%        21.300000\n",
      "max        44.700000\n"
     ]
    }
   ],
   "source": [
    "# No of rows and columns\n",
    "print('\\nNo of rows and columns: ', df_tp.shape)\n",
    "\n",
    "# Columns and datatypes\n",
    "print('\\nColumns and datatypes')\n",
    "print(df_tp.dtypes)\n",
    "\n",
    "# Describe the data\n",
    "print('\\nStatistics:')\n",
    "print(df_tp.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c942c981",
   "metadata": {},
   "source": [
    "---\n",
    "#### Remove unused columns\n",
    "\n",
    "As LOCATION is not useful for the research question, it is removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "881ba56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bankstown']\n"
     ]
    }
   ],
   "source": [
    "print(df_tp['LOCATION'].unique())\n",
    "\n",
    "df_tp = df_tp.drop(['LOCATION'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8098657e",
   "metadata": {},
   "source": [
    "---\n",
    "#### Validate Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "047427aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATETIME       0\n",
       "TEMPERATURE    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tp.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826d3e3f",
   "metadata": {},
   "source": [
    "---\n",
    "#### Validate Duplicate Rows\n",
    "\n",
    "Check for duplicated timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4cc2bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tp.duplicated(subset=['DATETIME']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5078e88c",
   "metadata": {},
   "source": [
    "Drop the duplicate records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4211f597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "df_tp = df_tp.drop_duplicates()\n",
    "\n",
    "print(df_tp.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6a1bf8",
   "metadata": {},
   "source": [
    "---\n",
    "#### Validate Missing Data\n",
    "\n",
    "a) Validate whether dates are missing between minimum date and maximum date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84aec70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Date:  2010-01-01\n",
      "Maximum Date:  2021-03-18\n",
      "Dates Missing:  3\n",
      "2016-07-16   2016-07-16\n",
      "2016-07-17   2016-07-17\n",
      "2016-07-18   2016-07-18\n",
      "dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Convert to DateTime datatype\n",
    "df_tp['DATETIME'] = pd.to_datetime(df_tp['DATETIME'], format='%d/%m/%Y %H:%M')\n",
    "df_tp_val = df_tp.copy()\n",
    "df_tp_val['DATE'] = df_tp['DATETIME'].dt.date\n",
    "\n",
    "# Find minimum and maximum values\n",
    "min_date = df_tp_val['DATE'].min()\n",
    "max_date = df_tp_val['DATE'].max()\n",
    "\n",
    "print(\"Minimum Date: \", min_date)\n",
    "print(\"Maximum Date: \", max_date)\n",
    "\n",
    "# generate all the dates in the calendar from min date to max date\n",
    "df_cal = pd.DataFrame({\"Calendar_Date\": pd.date_range(min_date, max_date)})\n",
    "\n",
    "print('Dates Missing: ', pd.date_range(min_date, max_date).difference(df_tp_val['DATE']).to_series().count())\n",
    "\n",
    "print(pd.date_range(min_date, max_date).difference(df_tp_val['DATE']).to_series())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7360b3",
   "metadata": {},
   "source": [
    "Three dates are missing. This is a very small percentage. The period use for model build should take this to consideration.\n",
    "\n",
    "b) Validate if temperature is recorded consistently for each date.\n",
    "\n",
    "Since demand is recorded every 30mins, each day should consist of 48 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3258d560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  DATETIME  TEMPERATURE        DATE      TIME\n",
      "0      2010-01-01 00:00:00         23.1  2010-01-01  00:00:00\n",
      "1      2010-01-01 00:01:00         23.1  2010-01-01  00:01:00\n",
      "2      2010-01-01 00:30:00         22.9  2010-01-01  00:30:00\n",
      "3      2010-01-01 00:50:00         22.7  2010-01-01  00:50:00\n",
      "4      2010-01-01 01:00:00         22.6  2010-01-01  01:00:00\n",
      "...                    ...          ...         ...       ...\n",
      "220321 2021-03-17 23:00:00         19.1  2021-03-17  23:00:00\n",
      "220322 2021-03-17 23:20:00         19.0  2021-03-17  23:20:00\n",
      "220323 2021-03-17 23:30:00         18.8  2021-03-17  23:30:00\n",
      "220324 2021-03-17 23:34:00         18.8  2021-03-17  23:34:00\n",
      "220325 2021-03-18 00:00:00         18.6  2021-03-18  00:00:00\n",
      "\n",
      "[158345 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df_tp_val['TIME'] = pd.to_datetime(df_tp['DATETIME'], format='%d/%m/%Y %H:%M').dt.time\n",
    "df_gp = df_tp_val.groupby('DATE').filter(lambda x: x['TIME'].count() != 48)\n",
    "print(df_gp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e33ab2",
   "metadata": {},
   "source": [
    "It seems the temperature readings are not restricted to hour and half hour intervals. \n",
    "Therefore lets verify whether every hour and half hour has a temperature reading.\n",
    "Also it should be noted that for 2021-03-18, there is only one record and it needs to be removed.\n",
    "\n",
    "Steps:\n",
    "\n",
    "* Create a half hourly date/time range from minimum date to maximum date - 1 (To exclude 1 record in 2021-03-18)\n",
    "* Left join temperature dataset to above dataset \n",
    "* Find records where temperature is null\n",
    "* Fill the missing values with fill forward method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e7a858c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records where Temperature is missing: 579\n",
      "\n",
      "Records where Temperature is missing after filling the missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# Create half hourly dataset\n",
    "max_date = max_date - pd.Timedelta(days=1)\n",
    "rng_hf_hr_cal = pd.date_range(start=min_date, end=max_date , freq='30min')\n",
    "df_hh_cal = pd.DataFrame(pd.to_datetime(rng_hf_hr_cal), columns=['DATETIME'])\n",
    "\n",
    "# Convert DATETIME column to datetime format\n",
    "df_tp['DATETIME'] = pd.to_datetime(df_tp['DATETIME'], format='%d/%m/%Y %H:%M')\n",
    "\n",
    "# Join the two datasets\n",
    "df_tp = pd.merge(df_hh_cal, df_tp, on='DATETIME', how='left')\n",
    "\n",
    "# find records with no temperature\n",
    "print('Records where Temperature is missing:', df_tp['TEMPERATURE'].isnull().sum())\n",
    "\n",
    "# fill null records with fill forward method\n",
    "df_tp['TEMPERATURE'] = df_tp['TEMPERATURE'].fillna(method='ffill')\n",
    "\n",
    "print('\\nRecords where Temperature is missing after filling the missing values:', df_tp['TEMPERATURE'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75853f1",
   "metadata": {},
   "source": [
    "---\n",
    "### **3. NSW Calendar**\n",
    "\n",
    "Using the python library for holidays lets create a calendar that is inline with the rest of the dataset.\n",
    "* Install 'holidays' library if it doesnt exist\n",
    "* Generate date range required and mark dates where it is a holiday in NSW\n",
    "* Add columns to identify seasons of the year. Use of one hot encoding\n",
    "* Add other columns such as MONTH, WEEKDAY, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8221ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: holidays in d:\\users\\rishantha\\anaconda3\\lib\\site-packages (0.56)\n",
      "Requirement already satisfied: python-dateutil in d:\\users\\rishantha\\anaconda3\\lib\\site-packages (from holidays) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\users\\rishantha\\anaconda3\\lib\\site-packages (from python-dateutil->holidays) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecb3d032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import holidays\n",
    "\n",
    "df_hd = pd.DataFrame({\"DATE\": pd.date_range(min_date, max_date)})\n",
    "df_hd.shape\n",
    "df_hd['HOLIDAY'] = (df_hd['DATE'].dt.date).apply(lambda x: 1 if x in holidays.Australia(prov='NSW') else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ff5fd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hd['SUMMER'] = (df_hd['DATE'].dt.month).apply(lambda x: 1 if x in [12, 1 ,2] else 0)\n",
    "df_hd['AUTUMN'] = (df_hd['DATE'].dt.month).apply(lambda x: 1 if x in [3, 4 ,5] else 0)\n",
    "df_hd['WINTER'] = (df_hd['DATE'].dt.month).apply(lambda x: 1 if x in [6, 7 ,8] else 0)\n",
    "df_hd['SPRING'] = (df_hd['DATE'].dt.month).apply(lambda x: 1 if x in [9, 10 ,11] else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "854ac1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           DATE  HOLIDAY  SUMMER  AUTUMN  WINTER  SPRING  MONTH  DAYOFWEEK  \\\n",
      "0    2010-01-01        1       1       0       0       0      1          4   \n",
      "1    2010-01-02        0       1       0       0       0      1          5   \n",
      "2    2010-01-03        0       1       0       0       0      1          6   \n",
      "3    2010-01-04        0       1       0       0       0      1          0   \n",
      "4    2010-01-05        0       1       0       0       0      1          1   \n",
      "...         ...      ...     ...     ...     ...     ...    ...        ...   \n",
      "4089 2021-03-13        0       0       1       0       0      3          5   \n",
      "4090 2021-03-14        0       0       1       0       0      3          6   \n",
      "4091 2021-03-15        0       0       1       0       0      3          0   \n",
      "4092 2021-03-16        0       0       1       0       0      3          1   \n",
      "4093 2021-03-17        0       0       1       0       0      3          2   \n",
      "\n",
      "      WEEKDAY  \n",
      "0           1  \n",
      "1           0  \n",
      "2           0  \n",
      "3           1  \n",
      "4           1  \n",
      "...       ...  \n",
      "4089        0  \n",
      "4090        0  \n",
      "4091        1  \n",
      "4092        1  \n",
      "4093        1  \n",
      "\n",
      "[4094 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "df_hd['MONTH'] = (df_hd['DATE'].dt.month)\n",
    "df_hd['DAYOFWEEK'] = (df_hd['DATE'].dt.dayofweek)\n",
    "df_hd['WEEKDAY'] = (df_hd['DATE'].dt.dayofweek).apply(lambda x: 0 if x in [5, 6] else 1)\n",
    "\n",
    "print(df_hd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f928e1a",
   "metadata": {},
   "source": [
    "---\n",
    "### **4. Total Forecast Demand NSW !!! TBC !!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f471aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d4512ad",
   "metadata": {},
   "source": [
    "---\n",
    "### **5. Final Dataset preperation**\n",
    "\n",
    "At completion of the data cleaning, lets cobmine the datasets and prepare the final dataset for exploitory data analysis and subsequent model build.\n",
    "\n",
    "Additionaly, include 'HOUR' and 'PEAK' feature. Here 'PEAK' is defined as 1 when the Time of the day is between 7:00 AM and 10:00 PM (https://www.canstarblue.com.au/electricity/peak-off-peak-electricity-times/).\n",
    "\n",
    "Finally, save the dataset to an csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db77c978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "df_tmp1 = df_td.merge(df_tp, on='DATETIME')\n",
    "df_tmp1['DATE'] = pd.to_datetime(df_tmp1['DATETIME'].dt.date)\n",
    "df_final = df_tmp1.merge(df_hd, on='DATE')\n",
    "df_final = df_final.drop('DATE', axis=1)\n",
    "df_final['HOUR'] = df_final['DATETIME'].dt.hour\n",
    "df_final['PEAK'] = df_final['HOUR'].apply(lambda x: 1 if 7 <= x < 22 else 0)\n",
    "df_final = df_final.set_index('DATETIME')\n",
    "\n",
    "df_final.to_csv('../data/final_data_2010_2021.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3362752",
   "metadata": {},
   "source": [
    "# 4. Assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65504d32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14803750",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
