{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3cbcdc5-23a9-49c1-9579-08065ae471ba",
   "metadata": {},
   "source": [
    "## NoteBook with Purely the LSTM Model contained - For testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab30ff97-d015-475d-b6c0-adad7b651020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136df8f1-0ed1-4212-b20c-d0d4d52d346b",
   "metadata": {},
   "source": [
    "# Import the DF's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13b926bf-af0a-4fe4-8efd-8d47a71e72eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecastdemand_vic = pd.read_csv(\"../data/Australia/a/forecastdemand_vic.csv\")\n",
    "forecastdemand_sa = pd.read_csv(\"../data/Australia/b/forecastdemand_sa.csv\")\n",
    "forecastdemand_qld = pd.read_csv(\"../data/Australia/c/forecastdemand_qld.csv\")\n",
    "temperature_qld = pd.read_csv(\"../data/Australia/d/temprature_qld.csv\")  # There's a typo in 'temperature' in the file path\n",
    "temperature_sa = pd.read_csv(\"../data/Australia/d/temprature_sa.csv\")  # Same typo as above\n",
    "temperature_vic = pd.read_csv(\"../data/Australia/d/temprature_vic.csv\")  # Same typo as above\n",
    "totaldemand_qld = pd.read_csv(\"../data/Australia/d/totaldemand_qld.csv\")\n",
    "totaldemand_sa = pd.read_csv(\"../data/Australia/d/totaldemand_sa.csv\")\n",
    "totaldemand_vic = pd.read_csv(\"../data/Australia/d/totaldemand_vic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1b8892d6-b2dc-4292-8b6a-12b8faddcb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecastdemand_qld['DATETIME'] = pd.to_datetime(forecastdemand_qld['DATETIME'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "temperature_qld['DATETIME'] = pd.to_datetime(temperature_qld['DATETIME'], format=\"%d/%m/%Y %H:%M\")\n",
    "totaldemand_qld['DATETIME'] = pd.to_datetime(totaldemand_qld['DATETIME'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0376ab9-e3c4-4337-b076-b49fce1b4c26",
   "metadata": {},
   "source": [
    "# Drop duplicates with latest last changed feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a11e489e-d12a-4c3e-8807-b12a0aa5a2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73833, 6)\n"
     ]
    }
   ],
   "source": [
    "forecastdemand_qld['LASTCHANGED'] = pd.to_datetime(forecastdemand_qld['LASTCHANGED'])\n",
    "forecastdemand_qld.sort_values(by='LASTCHANGED', ascending=False, inplace=True)\n",
    "forecastdemand_qld.drop_duplicates(subset='DATETIME', keep='first', inplace=True)\n",
    "print(forecastdemand_qld.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e631a72-d809-47f7-96af-afca8f313cd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PREDISPATCHSEQNO REGIONID_x  PERIODID  FORECASTDEMAND         LASTCHANGED  \\\n",
      "0        2021031740       QLD1         1         5714.08 2021-03-17 23:31:33   \n",
      "1        2021031739       QLD1         1         5924.06 2021-03-17 23:01:36   \n",
      "2        2021031738       QLD1         1         6148.23 2021-03-17 22:31:36   \n",
      "3        2021031737       QLD1         1         6309.79 2021-03-17 22:01:34   \n",
      "4        2021031736       QLD1         1         6459.56 2021-03-17 21:31:31   \n",
      "\n",
      "           DATETIME_x  YEAR  MONTH  DAY  HOUR  MINUTE          DATETIME_y  \\\n",
      "0 2021-03-18 00:00:00  2021      3   18     0       0 2021-03-18 00:00:00   \n",
      "1 2021-03-17 23:30:00  2021      3   17    23      30 2021-03-17 23:30:00   \n",
      "2 2021-03-17 23:00:00  2021      3   17    23       0 2021-03-17 23:00:00   \n",
      "3 2021-03-17 22:30:00  2021      3   17    22      30 2021-03-17 22:30:00   \n",
      "4 2021-03-17 22:00:00  2021      3   17    22       0 2021-03-17 22:00:00   \n",
      "\n",
      "   TOTALDEMAND REGIONID_y                      LOCATION            DATETIME  \\\n",
      "0      5737.03       QLD1  Brisbane Archerfield Airport 2021-03-18 00:00:00   \n",
      "1      5897.64       QLD1  Brisbane Archerfield Airport 2021-03-17 23:30:00   \n",
      "2      6144.16       QLD1  Brisbane Archerfield Airport 2021-03-17 23:00:00   \n",
      "3      6264.63       QLD1  Brisbane Archerfield Airport 2021-03-17 22:30:00   \n",
      "4      6443.62       QLD1  Brisbane Archerfield Airport 2021-03-17 22:00:00   \n",
      "\n",
      "   TEMPERATURE  \n",
      "0         19.5  \n",
      "1         19.6  \n",
      "2         19.4  \n",
      "3         19.5  \n",
      "4         19.6  \n"
     ]
    }
   ],
   "source": [
    "dataframes_qld = [forecastdemand_qld, totaldemand_qld, temperature_qld]\n",
    "\n",
    "for df in dataframes_qld:\n",
    "    df['YEAR'] = df['DATETIME'].dt.year\n",
    "    df['MONTH'] = df['DATETIME'].dt.month\n",
    "    df['DAY'] = df['DATETIME'].dt.day\n",
    "    df['HOUR'] = df['DATETIME'].dt.hour\n",
    "    df['MINUTE'] = df['DATETIME'].dt.minute\n",
    "\n",
    "merge_keys = ['YEAR', 'MONTH', 'DAY', 'HOUR', 'MINUTE']\n",
    "df_qld_merged = reduce(lambda left, right: pd.merge(left, right, on=merge_keys, how='inner'), dataframes_qld)\n",
    "\n",
    "print(df_qld_merged.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9bb1cb0-7e8c-48ab-b4e5-91457e6c9831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PREDISPATCHSEQNO', 'PERIODID', 'FORECASTDEMAND', 'LASTCHANGED', 'YEAR',\n",
      "       'MONTH', 'DAY', 'HOUR', 'MINUTE', 'DATETIME_y', 'TOTALDEMAND',\n",
      "       'REGIONID_y', 'LOCATION', 'DATETIME', 'TEMPERATURE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_qld_merged.drop(columns=['REGIONID_x', 'DATETIME_x'], inplace=True)\n",
    "print(df_qld_merged.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d326139e-5017-4d42-8468-4e2965b7688d",
   "metadata": {},
   "source": [
    "# Add in engineered features - Weekend and season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c5d9197-f424-4f43-96c5-55bbd94c8e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qld_merged['is_weekend'] = df_qld_merged['DATETIME'].dt.dayofweek >= 5\n",
    "\n",
    "df_qld_merged['season'] = df_qld_merged['DATETIME'].dt.month % 12 // 3\n",
    "df_qld_merged['season'] = df_qld_merged['season'].map({0: 'Summer', 1: 'Autumn', 2: 'Winter', 3: 'Spring'}, na_action='ignore')\n",
    "\n",
    "\n",
    "australian_seasons = {\n",
    "    12: 'Summer', 1: 'Summer', 2: 'Summer',\n",
    "    3: 'Autumn', 4: 'Autumn', 5: 'Autumn',\n",
    "    6: 'Winter', 7: 'Winter', 8: 'Winter',\n",
    "    9: 'Spring', 10: 'Spring', 11: 'Spring'\n",
    "    }\n",
    "df_qld_merged['season'] = df_qld_merged['MONTH'].map(australian_seasons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67855180-763c-4df2-889b-438854c65be3",
   "metadata": {},
   "source": [
    "# Add in a two more engineered features - Cooling and heating vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a0697e5-85f3-4c4f-9cdb-50b2d852bf79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Cooling  Heating\n",
      "0      0.0      0.5\n",
      "1      0.0      0.4\n",
      "2      0.0      0.6\n",
      "3      0.0      0.5\n",
      "4      0.0      0.4\n"
     ]
    }
   ],
   "source": [
    "df_qld_merged['Cooling'] = df_qld_merged['TEMPERATURE'].apply(lambda x: max(0, x - 24))\n",
    "\n",
    "df_qld_merged['Heating'] = df_qld_merged['TEMPERATURE'].apply(lambda x: max(0, 20 - x))\n",
    "\n",
    "print(df_qld_merged[['Cooling', 'Heating']].head())  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c45855-0293-4b38-9d8b-965ba79516d5",
   "metadata": {},
   "source": [
    "# Importing Public Holiday Data as another predictive Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e76be33-9003-4b6a-b6a9-c77fc9236975",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/public_holidays/Aus_public_hols_2009-2022-1.csv'\n",
    "try:\n",
    "    public_holidays = pd.read_csv(file_path, encoding='utf-8')\n",
    "except UnicodeDecodeError:\n",
    "    public_holidays = pd.read_csv(file_path, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2e50eafa-dd03-499e-9189-bc745c940d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1406 entries, 0 to 1405\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   Date           1406 non-null   datetime64[ns]\n",
      " 1   State          1406 non-null   object        \n",
      " 2   Weekday        1406 non-null   object        \n",
      " 3   Day_In_Lieu    1406 non-null   int64         \n",
      " 4   Part_Day_From  1406 non-null   int64         \n",
      "dtypes: datetime64[ns](1), int64(2), object(2)\n",
      "memory usage: 55.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "public_holidays['Date'] = pd.to_datetime(public_holidays['Date'])\n",
    "print(public_holidays.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bb4c29-1e30-4d33-8982-e4c1a25c7401",
   "metadata": {},
   "source": [
    "# Merging the public holiday data into the master QLD file (1 for public holiday, 0 for not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5298f5e9-0c32-4454-bda1-2ee988ab1fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PREDISPATCHSEQNO  PERIODID  FORECASTDEMAND         LASTCHANGED  YEAR  \\\n",
      "0        2021031740         1         5714.08 2021-03-17 23:31:33  2021   \n",
      "1        2021031739         1         5924.06 2021-03-17 23:01:36  2021   \n",
      "2        2021031738         1         6148.23 2021-03-17 22:31:36  2021   \n",
      "3        2021031737         1         6309.79 2021-03-17 22:01:34  2021   \n",
      "4        2021031736         1         6459.56 2021-03-17 21:31:31  2021   \n",
      "\n",
      "   MONTH  DAY  HOUR  MINUTE          DATETIME_y  TOTALDEMAND REGIONID_y  \\\n",
      "0      3   18     0       0 2021-03-18 00:00:00      5737.03       QLD1   \n",
      "1      3   17    23      30 2021-03-17 23:30:00      5897.64       QLD1   \n",
      "2      3   17    23       0 2021-03-17 23:00:00      6144.16       QLD1   \n",
      "3      3   17    22      30 2021-03-17 22:30:00      6264.63       QLD1   \n",
      "4      3   17    22       0 2021-03-17 22:00:00      6443.62       QLD1   \n",
      "\n",
      "                       LOCATION            DATETIME  TEMPERATURE  is_weekend  \\\n",
      "0  Brisbane Archerfield Airport 2021-03-18 00:00:00         19.5       False   \n",
      "1  Brisbane Archerfield Airport 2021-03-17 23:30:00         19.6       False   \n",
      "2  Brisbane Archerfield Airport 2021-03-17 23:00:00         19.4       False   \n",
      "3  Brisbane Archerfield Airport 2021-03-17 22:30:00         19.5       False   \n",
      "4  Brisbane Archerfield Airport 2021-03-17 22:00:00         19.6       False   \n",
      "\n",
      "   season  Cooling  Heating  Public_Holiday  \n",
      "0  Autumn      0.0      0.5               0  \n",
      "1  Autumn      0.0      0.4               0  \n",
      "2  Autumn      0.0      0.6               0  \n",
      "3  Autumn      0.0      0.5               0  \n",
      "4  Autumn      0.0      0.4               0  \n"
     ]
    }
   ],
   "source": [
    "public_holidays['Date'] = pd.to_datetime(public_holidays['Date'])\n",
    "qld_holidays = public_holidays[public_holidays['State'] == 'QLD']\n",
    "qld_holiday_dates = qld_holidays['Date'].dt.date.unique()\n",
    "df_qld_merged['DATETIME'] = pd.to_datetime(df_qld_merged['DATETIME'])\n",
    "df_qld_merged['Public_Holiday'] = df_qld_merged['DATETIME'].dt.date.isin(qld_holiday_dates).astype(int)\n",
    "print(df_qld_merged.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd51b129-41b7-49ee-9066-056f8554abb4",
   "metadata": {},
   "source": [
    "## Import the new DF that was created in the PV Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a7c4b1fa-34f5-4bd8-9d8c-7a4da0b361b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_PV_production = pd.read_csv('../data/PV_Data/raw_data/unzipped_data/combined_df_grouped_sorted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "012322e4-dc58-4434-8124-1f019838e37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "qld_solar_df = solar_PV_production[solar_PV_production['State'] == 'QLD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "093bb202-3512-4539-b6f5-f0a1b9562c39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bv/yhyl185564n2bzh9449xdfjw0000gn/T/ipykernel_9542/730933358.py:1: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  qld_solar_df['INTERVAL_DATETIME'] = pd.to_datetime(qld_solar_df['INTERVAL_DATETIME'], infer_datetime_format=True)\n",
      "/var/folders/bv/yhyl185564n2bzh9449xdfjw0000gn/T/ipykernel_9542/730933358.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  qld_solar_df['INTERVAL_DATETIME'] = pd.to_datetime(qld_solar_df['INTERVAL_DATETIME'], infer_datetime_format=True)\n"
     ]
    }
   ],
   "source": [
    "qld_solar_df['INTERVAL_DATETIME'] = pd.to_datetime(qld_solar_df['INTERVAL_DATETIME'], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1bed46b4-4177-4896-b350-f04de194fc21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "print(qld_solar_df['INTERVAL_DATETIME'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3221b6fc-66bc-44e5-a389-3d706a71c6b8",
   "metadata": {},
   "source": [
    "## Merge with the Master QLD DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "57c4d84f-dd6f-44e3-b27d-69c8ab0ef297",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_merged_df = df_qld_merged.merge(\n",
    "    qld_solar_df[['INTERVAL_DATETIME', 'POWER']], \n",
    "    how='left', \n",
    "    left_on='DATETIME', \n",
    "    right_on='INTERVAL_DATETIME'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9eb3c7a9-ee16-4305-8553-634ff7e5de68",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_merged_df.rename(columns={'POWER': 'Solar_Production'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a07f5af-cefd-4653-9b36-c899d29b4456",
   "metadata": {},
   "source": [
    "## Drop any rows where we dont have Solar Prod Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0a37e826-f492-4ee3-ad9b-b18a3aef4d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_merged_df = complete_merged_df.dropna(subset=['INTERVAL_DATETIME', 'Solar_Production'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2bbede-d827-4de4-bc4e-5e577a1709dd",
   "metadata": {},
   "source": [
    "## Finally Create LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "00cdae39-6e42-49b8-bba5-73cbbe2ab8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = ['YEAR', 'MONTH', 'DAY', 'HOUR', 'MINUTE', 'TEMPERATURE', 'Heating', 'Cooling', 'Solar_Production']\n",
    "categorical_features = ['season']\n",
    "binary_features = ['is_weekend', 'Public_Holiday']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features),\n",
    "        ('bin', 'passthrough', binary_features)\n",
    "    ])\n",
    "\n",
    "X = complete_merged_df.drop(['TOTALDEMAND'], axis=1)\n",
    "y = complete_merged_df['TOTALDEMAND'].values.reshape(-1, 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train.astype(np.float32))\n",
    "y_train_tensor = torch.tensor(y_train.astype(np.float32))\n",
    "X_test_tensor = torch.tensor(X_test.astype(np.float32))\n",
    "y_test_tensor = torch.tensor(y_test.astype(np.float32))\n",
    "\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "batch_size = 64  # You can adjust this size\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "492f9e27-c05d-4603-8275-162d6a26809c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Here x should have dimensions [batch, 1, features] - adding sequence dimension\n",
    "        x = x.unsqueeze(1)  \n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device) \n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)  \n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "input_dim = X_train.shape[1]  # number of features\n",
    "hidden_dim = 100  # can be changed\n",
    "num_layers = 2  # number of LSTM layers\n",
    "output_dim = 1  # one output\n",
    "num_epochs = 50\n",
    "model = LSTMModel(input_dim, hidden_dim, num_layers, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "344c61dc-cc78-4a2b-ac6f-2e241c80bfb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "68042c62-478d-478b-917b-4985502c5866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 32935598.0\n",
      "Epoch 2, Loss: 22509648.0\n",
      "Epoch 3, Loss: 20209946.0\n",
      "Epoch 4, Loss: 19002858.0\n",
      "Epoch 5, Loss: 16043596.0\n",
      "Epoch 6, Loss: 12169731.0\n",
      "Epoch 7, Loss: 8053302.0\n",
      "Epoch 8, Loss: 5716660.5\n",
      "Epoch 9, Loss: 7047811.5\n",
      "Epoch 10, Loss: 2865069.75\n",
      "Epoch 11, Loss: 3449994.0\n",
      "Epoch 12, Loss: 896480.8125\n",
      "Epoch 13, Loss: 2010407.625\n",
      "Epoch 14, Loss: 929408.3125\n",
      "Epoch 15, Loss: 1344079.625\n",
      "Epoch 16, Loss: 1461755.375\n",
      "Epoch 17, Loss: 1252422.5\n",
      "Epoch 18, Loss: 616108.3125\n",
      "Epoch 19, Loss: 1084384.375\n",
      "Epoch 20, Loss: 829844.75\n",
      "Epoch 21, Loss: 491212.59375\n",
      "Epoch 22, Loss: 1560848.125\n",
      "Epoch 23, Loss: 464143.40625\n",
      "Epoch 24, Loss: 430557.71875\n",
      "Epoch 25, Loss: 331889.59375\n",
      "Epoch 26, Loss: 343707.34375\n",
      "Epoch 27, Loss: 13451.72265625\n",
      "Epoch 28, Loss: 67671.0859375\n",
      "Epoch 29, Loss: 23286.591796875\n",
      "Epoch 30, Loss: 12850.04296875\n",
      "Epoch 31, Loss: 14345.3583984375\n",
      "Epoch 32, Loss: 70476.4609375\n",
      "Epoch 33, Loss: 14510.6181640625\n",
      "Epoch 34, Loss: 12591.5986328125\n",
      "Epoch 35, Loss: 71362.1953125\n",
      "Epoch 36, Loss: 14900.7294921875\n",
      "Epoch 37, Loss: 43952.16015625\n",
      "Epoch 38, Loss: 15041.8349609375\n",
      "Epoch 39, Loss: 5750.72216796875\n",
      "Epoch 40, Loss: 14192.4267578125\n",
      "Epoch 41, Loss: 8794.4833984375\n",
      "Epoch 42, Loss: 16126.7470703125\n",
      "Epoch 43, Loss: 16360.8701171875\n",
      "Epoch 44, Loss: 16082.8095703125\n",
      "Epoch 45, Loss: 13251.0400390625\n",
      "Epoch 46, Loss: 19873.685546875\n",
      "Epoch 47, Loss: 67161.46875\n",
      "Epoch 48, Loss: 38441.13671875\n",
      "Epoch 49, Loss: 7632.39453125\n",
      "Epoch 50, Loss: 12051.3154296875\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # If using GPU\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "02132121-71ab-4554-ad50-be28657ab426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 141.5611\n",
      "R^2 Score: 0.9745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshuaevans/opt/anaconda3/envs/2024_env/lib/python3.11/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "predictions = []\n",
    "targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        predictions.extend(outputs.view(-1).tolist())  # Flatten outputs to list\n",
    "        targets.extend(labels.view(-1).tolist())  # Flatten labels to list\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "targets = np.array(targets)\n",
    "\n",
    "rmse = mean_squared_error(targets, predictions, squared=False)\n",
    "r2 = r2_score(targets, predictions)\n",
    "\n",
    "print(f'RMSE: {rmse:.4f}')\n",
    "print(f'R^2 Score: {r2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bb08fe-fd10-423b-9107-8501cbf71657",
   "metadata": {},
   "source": [
    "## Make predictions based on data in the Master DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0bac856b-1780-4401-8634-5b1c417834c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessor.transform(complete_merged_df.drop(['TOTALDEMAND'], axis=1))\n",
    "\n",
    "X_tensor = torch.tensor(X.astype(np.float32)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "830c2998-3be7-4100-b431-dab72d1beadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # Ensure the model is in evaluation mode\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_tensor)\n",
    "    predictions = predictions.view(-1).cpu().numpy()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "813ee21a-01b5-43d4-ab64-a42a82753731",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_merged_df['LSTM_PREDICTED_DEMAND'] = predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1c4a669d-2687-4304-81c6-c4391ef24f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TOTALDEMAND  LSTM_PREDICTED_DEMAND  Error_LSTM  Error_Ratio_LSTM\n",
      "0      5737.03            5898.669922  161.639922          0.027403\n",
      "1      5897.64            6092.027344  194.387344          0.031908\n",
      "2      6144.16            6264.055664  119.895664          0.019140\n",
      "3      6264.63            6381.062500  116.432500          0.018247\n",
      "4      6443.62            6580.881348  137.261348          0.020858\n"
     ]
    }
   ],
   "source": [
    "\n",
    "complete_merged_df['Error_LSTM'] = complete_merged_df['LSTM_PREDICTED_DEMAND'] - complete_merged_df['TOTALDEMAND']\n",
    "\n",
    "complete_merged_df['Error_Ratio_LSTM'] = complete_merged_df['Error_LSTM'] / complete_merged_df['LSTM_PREDICTED_DEMAND']\n",
    "\n",
    "print(complete_merged_df[['TOTALDEMAND', 'LSTM_PREDICTED_DEMAND', 'Error_LSTM', 'Error_Ratio_LSTM']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4e471c19-df4d-4aa8-a6de-62b12ce8e63f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error_LSTM</th>\n",
       "      <th>Error_Ratio_LSTM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>53135.000000</td>\n",
       "      <td>53135.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-23.424650</td>\n",
       "      <td>-0.003660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>128.513832</td>\n",
       "      <td>0.019748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1385.848906</td>\n",
       "      <td>-0.227482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-92.131846</td>\n",
       "      <td>-0.015190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-20.021602</td>\n",
       "      <td>-0.003346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>49.859570</td>\n",
       "      <td>0.008334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1142.821953</td>\n",
       "      <td>0.135490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Error_LSTM  Error_Ratio_LSTM\n",
       "count  53135.000000      53135.000000\n",
       "mean     -23.424650         -0.003660\n",
       "std      128.513832          0.019748\n",
       "min    -1385.848906         -0.227482\n",
       "25%      -92.131846         -0.015190\n",
       "50%      -20.021602         -0.003346\n",
       "75%       49.859570          0.008334\n",
       "max     1142.821953          0.135490"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_merged_df[['Error_LSTM','Error_Ratio_LSTM']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2e3579-db0a-4fde-8db4-474480dcc11d",
   "metadata": {},
   "source": [
    "## Attemping to predict demand for yesterday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5abe6507-4497-429e-83d0-ee14e3cc240a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor shape: torch.Size([1, 15])\n",
      "Predicted total demand at 1 PM yesterday: 5219.572265625\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "data = {\n",
    "    'YEAR': [2024],\n",
    "    'MONTH': [4],\n",
    "    'DAY': [13],\n",
    "    'HOUR': [13],\n",
    "    'MINUTE': [0],\n",
    "    'TEMPERATURE': [26],\n",
    "    'Heating': [0],\n",
    "    'Cooling': [2],\n",
    "    'Solar_Production': [3660],\n",
    "    'season': ['Autumn'],\n",
    "    'is_weekend': [True],\n",
    "    'Public_Holiday': [False]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df_processed = preprocessor.transform(df)\n",
    "\n",
    "df_tensor = torch.tensor(df_processed.astype(np.float32))\n",
    "\n",
    "print(\"Original tensor shape:\", df_tensor.shape)\n",
    "\n",
    "df_tensor = df_tensor.view(1, -1)  # Shape: [1, number_of_features]\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    prediction = model(df_tensor)  # Pass the tensor, and let the model handle the reshaping\n",
    "\n",
    "print(\"Predicted total demand at 1 PM yesterday:\", prediction.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdc1c14-551c-46eb-a325-5a9b77833c95",
   "metadata": {},
   "source": [
    "## Prediction Demand for the Past Week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b054c607-53d3-43d9-b065-d98b78ff8eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted total demand for 8/4/2024 at 12 PM: 5945.32861328125\n",
      "Predicted total demand for 9/4/2024 at 12 PM: 5996.8271484375\n",
      "Predicted total demand for 10/4/2024 at 12 PM: 5920.494140625\n",
      "Predicted total demand for 11/4/2024 at 12 PM: 5813.892578125\n",
      "Predicted total demand for 12/4/2024 at 12 PM: 5238.0546875\n",
      "Predicted total demand for 13/4/2024 at 12 PM: 5290.056640625\n",
      "Predicted total demand for 14/4/2024 at 12 PM: 5369.7021484375\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'YEAR': [2024, 2024, 2024, 2024, 2024, 2024, 2024],\n",
    "    'MONTH': [4, 4, 4, 4, 4, 4, 4],\n",
    "    'DAY': [8, 9, 10, 11, 12, 13, 14],\n",
    "    'HOUR': [12, 12, 12, 12, 12, 12, 12],\n",
    "    'MINUTE': [0, 0, 0, 0, 0, 0, 0],\n",
    "    'TEMPERATURE': [28, 27, 25, 27, 27, 26, 27],\n",
    "    'Heating': [0, 0, 0, 0, 0, 0, 0],\n",
    "    'Cooling': [4, 3, 1, 3, 3, 2, 3],\n",
    "    'Solar_Production': [3523, 3141, 3854, 3738, 3437, 3218, 3256],\n",
    "    'season': ['Autumn', 'Autumn', 'Autumn', 'Autumn', 'Autumn', 'Autumn', 'Autumn'],\n",
    "    'is_weekend': [False, False, False, False, True, True, True],\n",
    "    'Public_Holiday': [False, False, False, False, False, False, False]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df_processed = preprocessor.transform(df)\n",
    "\n",
    "df_tensor = torch.tensor(df_processed.astype(np.float32))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(df_tensor.shape[0]):\n",
    "        single_input = df_tensor[i].unsqueeze(0)  # Add batch dimension\n",
    "        prediction = model(single_input)  # The model adds the sequence dimension internally\n",
    "        predictions.append(prediction.item())\n",
    "\n",
    "for i, pred in enumerate(predictions, start=1):\n",
    "    print(f\"Predicted total demand for {data['DAY'][i-1]}/{data['MONTH'][i-1]}/{data['YEAR'][i-1]} at 12 PM: {pred}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b21e712-cda5-4e48-b744-732d85322464",
   "metadata": {},
   "source": [
    "## Predicted Demand for the forward week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6901411e-7e13-4ca0-82e3-746a82adb823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted total demand for 15/4/2024 at 12 PM: 6010.04541015625\n",
      "Predicted total demand for 16/4/2024 at 12 PM: 6017.76904296875\n",
      "Predicted total demand for 17/4/2024 at 12 PM: 5993.50390625\n",
      "Predicted total demand for 18/4/2024 at 12 PM: 5935.2939453125\n",
      "Predicted total demand for 19/4/2024 at 12 PM: 5862.8291015625\n",
      "Predicted total demand for 20/4/2024 at 12 PM: 5780.4521484375\n",
      "Predicted total demand for 21/4/2024 at 12 PM: 5690.97802734375\n"
     ]
    }
   ],
   "source": [
    "new_data = {\n",
    "    'YEAR': [2024] * 7,\n",
    "    'MONTH': [4] * 7,\n",
    "    'DAY': [15, 16, 17, 18, 19, 20, 21],\n",
    "    'HOUR': [12] * 7,\n",
    "    'MINUTE': [0] * 7,\n",
    "    'TEMPERATURE': [27, 28, 27, 27, 27, 25, 25],\n",
    "    'Heating': [0, 0, 0, 0, 0, 0, 0],\n",
    "    'Cooling': [3, 4, 3, 3, 3, 1, 1],  # Corrected 'Cooling' values for the last two days\n",
    "    'Solar_Production': [2947, 3153, 2814, 2859, 2897, 2590, 2702],\n",
    "    'season': ['Autumn'] * 7,\n",
    "    'is_weekend': [False, False, False, False, False, True, True],\n",
    "    'Public_Holiday': [False, False, False, False, False, False, False]\n",
    "}\n",
    "\n",
    "new_df = pd.DataFrame(new_data)\n",
    "\n",
    "new_df_processed = preprocessor.transform(new_df)\n",
    "\n",
    "new_df_tensor = torch.tensor(new_df_processed.astype(np.float32))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "new_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(new_df_tensor.shape[0]):\n",
    "        single_input = new_df_tensor[i].unsqueeze(0)  # Add batch dimension\n",
    "        prediction = model(single_input)  # The model adds the sequence dimension internally\n",
    "        new_predictions.append(prediction.item())\n",
    "\n",
    "for i, pred in enumerate(new_predictions, start=1):\n",
    "    print(f\"Predicted total demand for {new_data['DAY'][i-1]}/{new_data['MONTH'][i-1]}/{new_data['YEAR'][i-1]} at 12 PM: {pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de05d0f-f8ae-4952-9596-865c8ebfe551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92e6917-a486-45a8-8ca6-cd79c11f0a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (2024_env)",
   "language": "python",
   "name": "2024_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
