{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring the Impacts of Residential And Commercial Solar Power Production on Grid Demand\n",
    "-------\n",
    "team: Group G – Watt’s Up Down Under\n",
    "session: Hexamester 2, 2024\n",
    "coursecode: ZZSC9020\n",
    "author: \n",
    "- Bernard Lo (z3464235)\n",
    "- Andrew Ryan (z2251397)\n",
    "- Chadi Abi Fadel (z5442788)\n",
    "- Joshua Evans (z5409600)\n",
    "\n",
    "\n",
    "# Abstract\n",
    "\n",
    "There is a well-known relationship between electricity demand and temperature in the electricity industry, most commercial power suppliers use temperature to forecast energy demand. More and more Australian homes are considering adding solar panels as a source of renewable energy, the team is interested in whether adding solar power as another variable will improve the accuracy of the model that is currently being used. By using convolutional neural network (CNN) and long short-term memory (LSTM) models, we improved the accuracy of the energy forecasting by implementing the solar power output dataset along with the temperature dataset that were originally used. Using temperature and solar power datasets from 2017 to 2021, the team concluded that both CNN and LSTM modelling techniques provided more accurate energy forecasting and comparing both models, LSTM is the superior model over CNN. The findings from this experiment suggested that energy providers should consider implementing datasets from various renewable sources to improve its modelling accuracy in order to improve energy pricing and reduce wastage.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the given dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our group's own python module is in `./src/watts_up`. It contains all the code required to run the functions called from `wup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing thhe python module.\n",
    "import src.watts_up as wup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unzpping Programmatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `wup.extract_all_zips(source_dir, dest_dir)`: Extracts all ZIP files from a specified source directory to a destination directory, creating the destination if it doesn't exist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_directory = '../data/Australia'\n",
    "destination_directory = '../extracted_zips'\n",
    "wup.extract_all_zips(source_directory, destination_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing CSVs to a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `wup.create_dataframes_dict(base_directory)`: Creates a dictionary of DataFrames from CSV files found in subdirectories of a base directory, keyed by CSV file names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = '../extracted_zips'  # Change this to your actual directory path\n",
    "dataframes_dict = wup.create_dataframes_dict(base_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- `wup.display_dataframes(dataframes)`: Displays basic information and the first few rows for each DataFrame in a given dictionary of DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wup.display_dataframes(dataframes_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframes organised by state in a dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- `wup.organize_and_print_dataframes(dataframes_dict)`: Organizes DataFrames by state based on naming conventions and prints out each DataFrame's name under its corresponding state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_by_state=wup.organize_and_print_dataframes(dataframes_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- `wup.get_dataframe_from_state(data_by_state, state, dataframe_key)`: Retrieves a specific DataFrame from a nested dictionary structure based on state and DataFrame key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is an example access to a dataframe from the dict using the function\n",
    "forecast_demand_vic=wup.get_dataframe_from_state(data_by_state, 'VIC', 'forecastdemand_vic')\n",
    "forecast_demand_vic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping PV data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "base_url = \"https://nemweb.com.au/Data_Archive/Wholesale_Electricity/MMSDM/\"\n",
    "\n",
    "years = range(2017, 2023)  \n",
    "months = [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"]\n",
    "\n",
    "file_prefix = \"PUBLIC_DVD_ROOFTOP_PV_ACTUAL_\"\n",
    "file_suffix = \".zip\"\n",
    "\n",
    "download_dir = Path(\"../data/PV_Data/raw_data\")  # The specified path\n",
    "download_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def download_file(url, path):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        with open(path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"Downloaded {file_name} to {path}\")\n",
    "    else:\n",
    "        print(f\"Failed to download {file_name}: HTTP Status Code {response.status_code}\")\n",
    "\n",
    "for year in years:\n",
    "    for month in months:\n",
    "        file_name = f\"{file_prefix}{year}{month}010000{file_suffix}\"\n",
    "        full_url = f\"{base_url}{year}/MMSDM_{year}_{month}/MMSDM_Historical_Data_SQLLoader/DATA/{file_name}\"\n",
    "        file_path = download_dir / file_name\n",
    "        \n",
    "        print(f\"Downloading {file_name}...\")\n",
    "        download_file(full_url, file_path)\n",
    "\n",
    "print(\"Downloads complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unzipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Specify the directory with the zip files\n",
    "zip_files_dir = Path(\"../data/PV_Data/raw_data\")\n",
    "unzip_dir = zip_files_dir / \"unzipped_data\"\n",
    "\n",
    "# Create a directory for the unzipped files if it doesn't exist\n",
    "unzip_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Loop through each zip file in the directory and unzip it\n",
    "for zip_file in zip_files_dir.glob(\"*.zip\"):\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        # Extract all the contents of zip file into the unzipped directory\n",
    "        zip_ref.extractall(unzip_dir)\n",
    "        print(f\"Unzipped {zip_file} into {unzip_dir}\")\n",
    "\n",
    "print(\"Unzipping complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing CSVs to a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = '../extracted_zips'  # Change this to your actual directory path\n",
    "dataframes_dict = wup.create_dataframes_dict(base_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wup.display_dataframes(dataframes_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframes organised by state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_by_state=wup.organize_and_print_dataframes(dataframes_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is an example access to a dataframe from the dict using the function\n",
    "forecast_demand_vic=wup.get_dataframe_from_state(data_by_state, 'VIC', 'forecastdemand_vic')\n",
    "forecast_demand_vic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect and Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wup.display_dataframes(dataframes_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframes organised by state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_by_state=wup.organize_and_print_dataframes(dataframes_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is an example access to a dataframe from the dict using the function\n",
    "forecast_demand_vic=wup.get_dataframe_from_state(data_by_state, 'VIC', 'forecastdemand_vic')\n",
    "forecast_demand_vic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_convert = ['LASTCHANGED', 'DATETIME']\n",
    "wup.convert_df_columns_to_datetime(data_by_state, columns_to_convert)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming 'data_by_state' is your nested dictionary structure\n",
    "columns_to_check = ['LASTCHANGED', 'DATETIME']\n",
    "wup.check_datetime_conversions(data_by_state, columns_to_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wup.print_missing_values_summary(data_by_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "# Appendix A: another trial to deal with duplicate QLD Forecasts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! TODO: automate the checks that there is not a high variance in the duplicate rows, if low variance, merge by mean\n",
    "sorted_unique_datetimes = np.sort(forecastdemand_qld['DATETIME'].unique())\n",
    "\n",
    "\n",
    "high_var=0\n",
    "cv=[]\n",
    "\n",
    "# variances\n",
    "for dt in sorted_unique_datetimes:\n",
    "    duplicate_readings=forecastdemand_qld[forecast_demand_vic['DATETIME'] == dt][['DATETIME','FORECASTDEMAND']]\n",
    "    std= duplicate_readings['FORECASTDEMAND'].std()\n",
    "    mean = duplicate_readings['FORECASTDEMAND'].mean()\n",
    "#     range_ratio=-(min(duplicate_readings['FORECASTDEMAND'])-max(duplicate_readings['FORECASTDEMAND']))/mean*2\n",
    "    coefficient_of_variation=std/mean\n",
    "    if (coefficient_of_variation>=0.1):\n",
    "        print (dt,'\\tVariance information')\n",
    "        print (\"std: \", std, \"mean :\", mean, \"coefficient_of_variation: \", coefficient_of_variation, 'min: ', min(duplicate_readings['FORECASTDEMAND']), \"MAX: \", max(duplicate_readings['FORECASTDEMAND']))\n",
    "        display (duplicate_readings)\n",
    "        high_var+=1\n",
    "        if (high_var>=5):\n",
    "            break\n",
    "    cv.append(coefficient_of_variation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_cv = sum(cv) / len(cv)\n",
    "\n",
    "print(\"Average:\", average_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping by mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'ID' and calculate the mean of 'Value', keeping 'Other' column as is (if needed)\n",
    "unique_forcastdemand_qld = forecastdemand_qld.groupby('DATETIME', as_index=False).agg({'FORECASTDEMAND': 'mean', 'PERIODID': 'first'})\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(\"\\nDataFrame after dropping duplicates by mean of 'Value':\")\n",
    "display(unique_forcastdemand_qld)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
