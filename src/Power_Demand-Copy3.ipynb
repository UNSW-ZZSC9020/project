{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc4635a1-f7cf-4859-9161-4318929ec5ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "color_pal = sns.color_palette()\n",
    "\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7bd308-f90b-4ca3-b3b8-c782d2f99214",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import Data Files for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d22ea8a-17d9-4881-aa93-65771a73673b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temperature_vic = pd.read_csv(\"C:/Users/aryan2/Assessment Data/temperature_vic.csv\")\n",
    "temperature_qld = pd.read_csv(\"C:/Users/aryan2/Assessment Data/temperature_qld.csv\")\n",
    "temperature_sa = pd.read_csv(\"C:/Users/aryan2/Assessment Data/temperature_sa.csv\")\n",
    "forecastdemand_vic = pd.read_csv(\"C:/Users/aryan2/Assessment Data/forecastdemand_vic.csv\")\n",
    "forecastdemand_qld = pd.read_csv(\"C:/Users/aryan2/Assessment Data/forecastdemand_qld.csv\")\n",
    "forecastdemand_sa = pd.read_csv(\"C:/Users/aryan2/Assessment Data/forecastdemand_sa.csv\")\n",
    "totaldemand_vic = pd.read_csv(\"C:/Users/aryan2/Assessment Data/totaldemand_vic.csv\")\n",
    "totaldemand_qld = pd.read_csv(\"C:/Users/aryan2/Assessment Data/totaldemand_qld.csv\")\n",
    "totaldemand_sa = pd.read_csv(\"C:/Users/aryan2/Assessment Data/totaldemand_sa.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3a9c80-2194-41b1-851e-db92d1bdf450",
   "metadata": {},
   "source": [
    "## Inspect and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1bfce2c4-0857-4a5d-bb39-80da387aa80f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate count in demand_vic = 4021759 out of 4095592 records\n",
      "Duplicate count in temperature_vic = 0 out of 141681 records\n",
      "Duplicate count in totaldemand_vic = 0 out of 196513 records\n"
     ]
    }
   ],
   "source": [
    "# For demand_vic\n",
    "total_records_demand_vic = len(forecastdemand_vic)\n",
    "duplicate_count_demand_vic = forecastdemand_vic.duplicated('DATETIME').sum()\n",
    "print(\"Duplicate count in demand_vic = {} out of {} records\".format(duplicate_count_demand_vic, total_records_demand_vic))\n",
    "\n",
    "# For temperature_vic\n",
    "total_records_temp_vic = len(temperature_vic)\n",
    "duplicate_count_temp_vic = temperature_vic.duplicated('DATETIME').sum()\n",
    "print(\"Duplicate count in temperature_vic = {} out of {} records\".format(duplicate_count_temp_vic, total_records_temp_vic))\n",
    "\n",
    "# For totaldemand_vic\n",
    "total_records_totaldemand_vic = len(totaldemand_vic)\n",
    "duplicate_count_totaldemand_vic = totaldemand_vic.duplicated('DATETIME').sum()\n",
    "print(\"Duplicate count in totaldemand_vic = {} out of {} records\".format(duplicate_count_totaldemand_vic, total_records_totaldemand_vic))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "418066a1-3a54-4b4c-a600-278f30a54b7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate count in demand_sa = 0 out of 73833 records\n",
      "Duplicate count in temperature_sa = 0 out of 208085 records\n",
      "Duplicate count in totaldemand_sa = 0 out of 196512 records\n"
     ]
    }
   ],
   "source": [
    "# For demand_sa\n",
    "total_records_demand_sa = len(forecastdemand_sa)\n",
    "duplicate_count_demand_sa = forecastdemand_sa.duplicated('DATETIME').sum()\n",
    "print(\"Duplicate count in demand_sa = {} out of {} records\".format(duplicate_count_demand_sa, total_records_demand_sa))\n",
    "\n",
    "# For temperature_sa\n",
    "total_records_temp_sa = len(temperature_sa)\n",
    "duplicate_count_temp_sa = temperature_sa.duplicated('DATETIME').sum()\n",
    "print(\"Duplicate count in temperature_sa = {} out of {} records\".format(duplicate_count_temp_sa, total_records_temp_sa))\n",
    "\n",
    "# For totaldemand_sa\n",
    "total_records_totaldemand_sa = len(totaldemand_sa)\n",
    "duplicate_count_totaldemand_sa = totaldemand_sa.duplicated('DATETIME').sum()\n",
    "print(\"Duplicate count in totaldemand_sa = {} out of {} records\".format(duplicate_count_totaldemand_sa, total_records_totaldemand_sa))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd2031d3-6b7c-4ca8-890e-422eb5a43247",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate count in demand_qld = 4021759 out of 4095592 records\n",
      "Duplicate count in temperature_qld = 0 out of 208085 records\n",
      "Duplicate count in totaldemand_qld = 0 out of 196513 records\n"
     ]
    }
   ],
   "source": [
    "# For demand_qld\n",
    "total_records_demand_qld = len(forecastdemand_qld)\n",
    "duplicate_count_demand_qld = forecastdemand_qld.duplicated('DATETIME').sum()\n",
    "print(\"Duplicate count in demand_qld = {} out of {} records\".format(duplicate_count_demand_qld, total_records_demand_qld))\n",
    "\n",
    "# For temperature_qld\n",
    "total_records_temp_qld = len(temperature_qld)\n",
    "duplicate_count_temp_qld = temperature_qld.duplicated('DATETIME').sum()\n",
    "print(\"Duplicate count in temperature_qld = {} out of {} records\".format(duplicate_count_temp_qld, total_records_temp_qld))\n",
    "\n",
    "# For totaldemand_qld\n",
    "total_records_totaldemand_qld = len(totaldemand_qld)\n",
    "duplicate_count_totaldemand_qld = totaldemand_qld.duplicated('DATETIME').sum()\n",
    "print(\"Duplicate count in totaldemand_qld = {} out of {} records\".format(duplicate_count_totaldemand_qld, total_records_totaldemand_qld))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16785649-749f-4421-85a0-9b9719f30b5a",
   "metadata": {},
   "source": [
    "# Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "70962149-1fe3-4f82-b159-225805f3254e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original forecastdemand_qld shape: (4095592, 6)\n",
      "forecastdemand_qld shape after removing duplicates: (73833, 6)\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates from forecastdemand_qld\n",
    "forecastdemand_qld_no_duplicates = forecastdemand_qld.drop_duplicates(subset='DATETIME', keep='last')\n",
    "\n",
    "# Extract duplicates from forecastdemand_qld\n",
    "duplicates_forecastdemand_qld = forecastdemand_qld[~forecastdemand_qld.index.isin(forecastdemand_qld_no_duplicates.index)]\n",
    "\n",
    "# Save duplicates to a CSV file\n",
    "duplicates_forecastdemand_qld.to_csv(\"forecastdemand_qld_duplicates.csv\", index=False)\n",
    "\n",
    "# Verify that duplicates are removed from forecastdemand_qld\n",
    "print(\"Original forecastdemand_qld shape:\", forecastdemand_qld.shape)\n",
    "print(\"forecastdemand_qld shape after removing duplicates:\", forecastdemand_qld_no_duplicates.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1484f081-6313-43cd-8a58-237a68b8c37a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original forecastdemand_vic shape: (4095592, 6)\n",
      "forecastdemand_vic shape after removing duplicates: (73833, 6)\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates from forecastdemand_vic\n",
    "forecastdemand_vic_no_duplicates = forecastdemand_vic.drop_duplicates(subset='DATETIME', keep='last')\n",
    "\n",
    "# Extract duplicates from forecastdemand_qld\n",
    "duplicates_forecastdemand_vic = forecastdemand_vic[~forecastdemand_vic.index.isin(forecastdemand_vic_no_duplicates.index)]\n",
    "\n",
    "# Save duplicates to a CSV file\n",
    "duplicates_forecastdemand_vic.to_csv(\"forecastdemand_vic_duplicates.csv\", index=False)\n",
    "\n",
    "# Verify that duplicates are removed from forecastdemand_qld\n",
    "print(\"Original forecastdemand_vic shape:\", forecastdemand_vic.shape)\n",
    "print(\"forecastdemand_vic shape after removing duplicates:\", forecastdemand_vic_no_duplicates.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264a190c-c78e-41ec-90ef-dd3542817a8d",
   "metadata": {},
   "source": [
    "## Copy the remove duplicate values list back to the master lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "45e1b9e7-701f-4e34-8a58-9a79f37b5e9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "forecastdemand_qld = forecastdemand_qld_no_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "47cba0a0-d59d-45b7-af3c-2caf3029a668",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PREDISPATCHSEQNO</th>\n",
       "      <th>PERIODID</th>\n",
       "      <th>FORECASTDEMAND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.383300e+04</td>\n",
       "      <td>73833.000000</td>\n",
       "      <td>73833.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.018690e+09</td>\n",
       "      <td>1.021765</td>\n",
       "      <td>6212.168522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.214770e+06</td>\n",
       "      <td>0.902165</td>\n",
       "      <td>896.399377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.016123e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3764.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.018012e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5505.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.019021e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6102.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.020023e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6815.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.021032e+09</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>9964.840000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PREDISPATCHSEQNO      PERIODID  FORECASTDEMAND\n",
       "count      7.383300e+04  73833.000000    73833.000000\n",
       "mean       2.018690e+09      1.021765     6212.168522\n",
       "std        1.214770e+06      0.902165      896.399377\n",
       "min        2.016123e+09      1.000000     3764.770000\n",
       "25%        2.018012e+09      1.000000     5505.050000\n",
       "50%        2.019021e+09      1.000000     6102.770000\n",
       "75%        2.020023e+09      1.000000     6815.450000\n",
       "max        2.021032e+09     57.000000     9964.840000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastdemand_qld.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d9f8fbf-b6f4-45ab-bd47-7073b4a37bff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "forecastdemand_vic = forecastdemand_vic_no_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "66865e5f-37fb-42c4-8964-77455412c699",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PREDISPATCHSEQNO</th>\n",
       "      <th>PERIODID</th>\n",
       "      <th>FORECASTDEMAND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.383300e+04</td>\n",
       "      <td>73833.000000</td>\n",
       "      <td>73833.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.018690e+09</td>\n",
       "      <td>1.021765</td>\n",
       "      <td>4889.051609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.214770e+06</td>\n",
       "      <td>0.902165</td>\n",
       "      <td>869.253987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.016123e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2354.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.018012e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4238.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.019021e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4788.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.020023e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5398.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.021032e+09</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>9580.890000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PREDISPATCHSEQNO      PERIODID  FORECASTDEMAND\n",
       "count      7.383300e+04  73833.000000    73833.000000\n",
       "mean       2.018690e+09      1.021765     4889.051609\n",
       "std        1.214770e+06      0.902165      869.253987\n",
       "min        2.016123e+09      1.000000     2354.240000\n",
       "25%        2.018012e+09      1.000000     4238.980000\n",
       "50%        2.019021e+09      1.000000     4788.080000\n",
       "75%        2.020023e+09      1.000000     5398.370000\n",
       "max        2.021032e+09     57.000000     9580.890000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastdemand_vic.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "03bf17ff-d9e4-46b1-a37a-60900a1e69cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PREDISPATCHSEQNO</th>\n",
       "      <th>PERIODID</th>\n",
       "      <th>FORECASTDEMAND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.383300e+04</td>\n",
       "      <td>73833.000000</td>\n",
       "      <td>73833.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.018687e+09</td>\n",
       "      <td>55.502377</td>\n",
       "      <td>1282.122297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.215063e+06</td>\n",
       "      <td>13.854351</td>\n",
       "      <td>331.538480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.016123e+09</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>194.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.018012e+09</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>1083.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.019021e+09</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>1253.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.020023e+09</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>1448.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.021032e+09</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>3081.020000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PREDISPATCHSEQNO      PERIODID  FORECASTDEMAND\n",
       "count      7.383300e+04  73833.000000    73833.000000\n",
       "mean       2.018687e+09     55.502377     1282.122297\n",
       "std        1.215063e+06     13.854351      331.538480\n",
       "min        2.016123e+09     32.000000      194.630000\n",
       "25%        2.018012e+09     44.000000     1083.040000\n",
       "50%        2.019021e+09     56.000000     1253.840000\n",
       "75%        2.020023e+09     68.000000     1448.900000\n",
       "max        2.021032e+09     79.000000     3081.020000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecastdemand_sa.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ded0a0a-8815-47eb-859e-379992a17d3d",
   "metadata": {},
   "source": [
    "## Now the count of records in all 3 x states are equal!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5882e98-404c-4f74-a77b-33515008d524",
   "metadata": {},
   "source": [
    "## Part 2 Merging Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52c2f3a-f2ee-4e37-aceb-49594c9571c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Start with South Australia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b06fc1f3-145f-492f-9dcb-b7f4edcdc7fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Date: 2010-01-01 00:00:00\n",
      "Maximum Date: 2021-03-18 00:00:00\n",
      "Average Time Between Samples: 0 days 00:28:19.898118067\n"
     ]
    }
   ],
   "source": [
    "temperature_sa['DATETIME'] = pd.to_datetime(temperature_sa['DATETIME'])\n",
    "\n",
    "# Minimum and maximum dates\n",
    "min_date = temperature_sa['DATETIME'].min()\n",
    "max_date = temperature_sa['DATETIME'].max()\n",
    "\n",
    "# Average time between each time sample\n",
    "time_diff = temperature_sa['DATETIME'].diff().mean()\n",
    "\n",
    "print(\"Minimum Date:\", min_date)\n",
    "print(\"Maximum Date:\", max_date)\n",
    "print(\"Average Time Between Samples:\", time_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d216cda-53e4-4b36-9d02-14c393db07a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert 'DATETIME' column to datetime type if it's not already\n",
    "totaldemand_sa['DATETIME'] = pd.to_datetime(totaldemand_sa['DATETIME'])\n",
    "\n",
    "# Minimum and maximum dates\n",
    "min_date = totaldemand_sa['DATETIME'].min()\n",
    "max_date = totaldemand_sa['DATETIME'].max()\n",
    "\n",
    "# Average time between each time sample\n",
    "time_diff = totaldemand_sa['DATETIME'].diff().mean()\n",
    "\n",
    "print(\"Minimum Date:\", min_date)\n",
    "print(\"Maximum Date:\", max_date)\n",
    "print(\"Average Time Between Samples:\", time_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3cbaad-d12e-4ed8-8c3e-78cd7193aaf1",
   "metadata": {},
   "source": [
    "### Stopped Here Today - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d4e97769-d041-4639-8d30-8ca3c6661596",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Date: 2017-01-01 00:00:00\n",
      "Maximum Date: 2021-03-19 04:00:00\n",
      "Average Time Between Samples: 0 days 00:30:00\n"
     ]
    }
   ],
   "source": [
    "# Convert 'DATETIME' column to datetime type if it's not already\n",
    "forecastdemand_qld['DATETIME'] = pd.to_datetime(forecastdemand_qld['DATETIME'])\n",
    "\n",
    "# Minimum and maximum dates\n",
    "min_date = forecastdemand_qld['DATETIME'].min()\n",
    "max_date = forecastdemand_qld['DATETIME'].max()\n",
    "\n",
    "# Average time between each time sample\n",
    "time_diff = forecastdemand_qld['DATETIME'].diff().mean()\n",
    "\n",
    "print(\"Minimum Date:\", min_date)\n",
    "print(\"Maximum Date:\", max_date)\n",
    "print(\"Average Time Between Samples:\", time_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5de7c3bb-2b7d-4e5d-bde7-a5a55c7f4a93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Date: 2017-01-01 00:00:00\n",
      "Maximum Date: 2021-03-19 04:00:00\n",
      "Average Time Between Samples: 0 days 00:30:00\n"
     ]
    }
   ],
   "source": [
    "# Convert 'DATETIME' column to datetime type if it's not already\n",
    "forecastdemand_qld['DATETIME'] = pd.to_datetime(forecastdemand_qld['DATETIME'])\n",
    "\n",
    "# Minimum and maximum dates\n",
    "min_date = forecastdemand_qld['DATETIME'].min()\n",
    "max_date = forecastdemand_qld['DATETIME'].max()\n",
    "\n",
    "# Average time between each time sample\n",
    "time_diff = forecastdemand_qld['DATETIME'].diff().mean()\n",
    "\n",
    "print(\"Minimum Date:\", min_date)\n",
    "print(\"Maximum Date:\", max_date)\n",
    "print(\"Average Time Between Samples:\", time_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6124653-aadd-4109-b2b2-1ca89f802a95",
   "metadata": {},
   "source": [
    "#QLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "591c40a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert 'DATETIME' column to datetime type if it's not already\n",
    "totaldemand_sa['DATETIME'] = pd.to_datetime(totaldemand_sa['DATETIME'])\n",
    "\n",
    "# Minimum and maximum dates\n",
    "min_date = totaldemand_sa['DATETIME'].min()\n",
    "max_date = totaldemand_sa['DATETIME'].max()\n",
    "\n",
    "# Average time between each time sample\n",
    "time_diff = totaldemand_sa['DATETIME'].diff().mean()\n",
    "\n",
    "print(\"Minimum Date:\", min_date)\n",
    "print(\"Maximum Date:\", max_date)\n",
    "print(\"Average Time Between Samples:\", time_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2616a4c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Date: 2017-01-01 00:00:00\n",
      "Maximum Date: 2021-03-19 04:00:00\n",
      "Average Time Between Samples: 0 days 00:30:00\n"
     ]
    }
   ],
   "source": [
    "# Convert 'DATETIME' column to datetime type if it's not already\n",
    "forecastdemand_qld['DATETIME'] = pd.to_datetime(forecastdemand_qld['DATETIME'])\n",
    "\n",
    "# Minimum and maximum dates\n",
    "min_date = forecastdemand_qld['DATETIME'].min()\n",
    "max_date = forecastdemand_qld['DATETIME'].max()\n",
    "\n",
    "# Average time between each time sample\n",
    "time_diff = forecastdemand_qld['DATETIME'].diff().mean()\n",
    "\n",
    "print(\"Minimum Date:\", min_date)\n",
    "print(\"Maximum Date:\", max_date)\n",
    "print(\"Average Time Between Samples:\", time_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58d34d3-5753-4b18-a5e0-bdbdca5ccd3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5353fd78-9316-4c0a-abce-a4ac5eae2f62",
   "metadata": {},
   "source": [
    "## Explore Dataset - Plot a Month worth of Temperature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175f4ee0-443c-4eb9-b5c0-a65569112cd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert 'DATETIME' column to datetime type if it's not already\n",
    "temperature_sa['DATETIME'] = pd.to_datetime(temperature_sa['DATETIME'])\n",
    "\n",
    "# Filter data for a single month (for example, January 2024)\n",
    "start_date = '2010-01-01'\n",
    "end_date = '2010-01-31'\n",
    "temperature_sa_single_month = temperature_sa[(temperature_sa['DATETIME'] >= start_date) & (temperature_sa['DATETIME'] <= end_date)]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(temperature_sa_single_month['DATETIME'], temperature_sa_single_month['TEMPERATURE'], marker='o', linestyle='-')\n",
    "plt.title('Temperature vs. Datetime (January 2010)')\n",
    "plt.xlabel('Datetime')\n",
    "plt.ylabel('Temperature')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86520f64-0cdf-4127-a3e0-49d7b94ec7f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert 'DATETIME' column to datetime type if it's not already\n",
    "totaldemand_sa['DATETIME'] = pd.to_datetime(totaldemand_sa['DATETIME'])\n",
    "\n",
    "# Filter data for a single month (for example, January 2024)\n",
    "start_date = '2010-01-01'\n",
    "end_date = '2010-03-31'\n",
    "totaldemand_sa_single_month = totaldemand_sa[(totaldemand_sa['DATETIME'] >= start_date) & (totaldemand_sa['DATETIME'] <= end_date)]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(totaldemand_sa_single_month['DATETIME'], totaldemand_sa_single_month['TOTALDEMAND'], marker='o', linestyle='-')\n",
    "plt.title('TOTALDEMAND vs. Datetime (January - March 2010)')\n",
    "plt.xlabel('Datetime')\n",
    "plt.ylabel('TOTALDEMAND')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c7f8a8-f14f-410b-9b7c-5da22098650b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sa_df = pd.merge(temperature_sa, totaldemand_sa, on='DATETIME', how='inner')\n",
    "\n",
    "# Merge merged_df with forecastdemand_sa on 'DATETIME'\n",
    "sa_df = pd.merge(sa_df, forecastdemand_sa, on='DATETIME', how='inner')\n",
    "\n",
    "print(sa_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305d562a-692b-4a85-aa4f-cfb5b5848e8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temperature_sa['DATETIME'] = pd.to_datetime(temperature_sa['DATETIME'])\n",
    "\n",
    "# Minimum and maximum dates\n",
    "min_date = temperature_sa['DATETIME'].min()\n",
    "max_date = temperature_sa['DATETIME'].max()\n",
    "\n",
    "# Average time between each time sample\n",
    "time_diff = temperature_sa['DATETIME'].diff().mean()\n",
    "\n",
    "print(\"Minimum Date:\", min_date)\n",
    "print(\"Maximum Date:\", max_date)\n",
    "print(\"Average Time Between Samples:\", time_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a23f330-3379-4485-9447-14a1aa182dcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert 'DATETIME' column to datetime type if it's not already\n",
    "sa_df['DATETIME'] = pd.to_datetime(sa_df['DATETIME'])\n",
    "\n",
    "# Find the index of the first date after the minimum date\n",
    "start_index = sa_df.index[sa_df['DATETIME'] >= '2017-01-01 00:00:00'][0]\n",
    "\n",
    "# Find the index of the last date before the maximum date\n",
    "end_index = sa_df.index[sa_df['DATETIME'] <= '2021-03-18 00:00:00'][-1]\n",
    "\n",
    "# Slice the DataFrame to keep only the values within the specified date range\n",
    "sa_df = sa_df[start_index:end_index+1]\n",
    "\n",
    "print(sa_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eeab1ea-8ebd-4b4c-8497-970205905cc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "column_names = sa_df.columns.tolist()\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae0ef80-6a11-4b52-91bb-f4eab46953b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check for null or missing values\n",
    "null_values = sa_df.isnull().any()\n",
    "\n",
    "# Print columns with missing values\n",
    "print(\"Columns with missing values:\")\n",
    "print(null_values[null_values])\n",
    "\n",
    "# Count total missing values\n",
    "total_missing = sa_df.isnull().sum().sum()\n",
    "print(\"Total missing values:\", total_missing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e31e58-5fee-44aa-8b6b-b87549d5a259",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the correlation between TEMPERATURE and TOTALDEMAND\n",
    "correlation = sa_df['TEMPERATURE'].corr(sa_df['TOTALDEMAND'])\n",
    "\n",
    "print(\"Correlation between TEMPERATURE and TOTALDEMAND:\", correlation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333d99da-c72c-43c4-906f-45483307de9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(sa_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf2d432-c19e-46df-a34e-c289441d3f77",
   "metadata": {},
   "source": [
    "# Further data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36858491-150a-4532-8f34-0554b855b149",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Scatter Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x='TEMPERATURE', y='TOTALDEMAND', data=sa_df)\n",
    "plt.title('Scatter Plot of TEMPERATURE vs TOTALDEMAND')\n",
    "plt.xlabel('TEMPERATURE')\n",
    "plt.ylabel('TOTALDEMAND')\n",
    "plt.show()\n",
    "\n",
    "# Line Plot\n",
    "# Create figure and axis objects\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot TOTALDEMAND on the primary y-axis\n",
    "sns.lineplot(x=sa_df.index, y='TOTALDEMAND', data=sa_df, label='TOTALDEMAND', ax=ax1, color='b')\n",
    "ax1.set_ylabel('TOTALDEMAND', color='b')\n",
    "ax1.tick_params('y', colors='b')\n",
    "\n",
    "# Create a secondary y-axis for TEMPERATURE\n",
    "ax2 = ax1.twinx()\n",
    "sns.lineplot(x=sa_df.index, y='TEMPERATURE', data=sa_df, label='TEMPERATURE', ax=ax2, color='r')\n",
    "ax2.set_ylabel('TEMPERATURE', color='r')\n",
    "ax2.tick_params('y', colors='r')\n",
    "\n",
    "# Set titles and legend\n",
    "plt.title('Line Plot of TOTALDEMAND and TEMPERATURE')\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.legend(loc='upper left')\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Box Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x=pd.cut(sa_df['TEMPERATURE'], bins=5), y='TOTALDEMAND', data=sa_df)\n",
    "plt.title('Box Plot of TOTALDEMAND by TEMPERATURE Ranges')\n",
    "plt.xlabel('TEMPERATURE Range')\n",
    "plt.ylabel('TOTALDEMAND')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(sa_df['TEMPERATURE'], bins=20, kde=True)\n",
    "plt.title('Distribution of TEMPERATURE')\n",
    "plt.xlabel('TEMPERATURE')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(sa_df['TOTALDEMAND'], bins=20, kde=True)\n",
    "plt.title('Distribution of TOTALDEMAND')\n",
    "plt.xlabel('TOTALDEMAND')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15c7f29-0933-4595-a950-47c66fa894a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Check NEW DF for null or missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2c8223-ed2a-4fba-ada4-511c58a48ba1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter data for January 2017\n",
    "january_2017_df = sa_df[(sa_df['DATETIME'] >= '2017-01-01') & (sa_df['DATETIME'] <= '2017-01-31')]\n",
    "\n",
    "# Plotting\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Primary y-axis (left)\n",
    "ax1.plot(january_2017_df['DATETIME'], january_2017_df['FORECASTDEMAND'], label='Forecast Demand', color='blue')\n",
    "ax1.plot(january_2017_df['DATETIME'], january_2017_df['TOTALDEMAND'], label='Total Demand', color='green')\n",
    "ax1.set_xlabel('Datetime')\n",
    "ax1.set_ylabel('Demand', color='black')\n",
    "ax1.tick_params('y', colors='black')\n",
    "ax1.legend(loc='upper left')\n",
    "\n",
    "# Secondary y-axis (right) for temperature\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(january_2017_df['DATETIME'], january_2017_df['TEMPERATURE'], label='Temperature', color='red')\n",
    "ax2.set_ylabel('Temperature', color='black')\n",
    "ax2.tick_params('y', colors='black')\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "plt.title('Demand and Temperature for January 2017')\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87df587f-8aa6-4adb-81a3-f00415513661",
   "metadata": {},
   "source": [
    "## Add in additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e10adbb-04c9-432d-a94d-fa6a26c40b34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a function to map months to seasons in Australia\n",
    "def get_season_australia(month):\n",
    "    if 1 <= month <= 2 or month == 12:\n",
    "        return 'Summer'\n",
    "    elif 3 <= month <= 5:\n",
    "        return 'Autumn'\n",
    "    elif 6 <= month <= 8:\n",
    "        return 'Winter'\n",
    "    else:\n",
    "        return 'Spring'\n",
    "\n",
    "# Extract month from DATETIME column\n",
    "sa_df['MONTH'] = sa_df['DATETIME'].dt.month\n",
    "\n",
    "# Map months to seasons for Australia\n",
    "sa_df['SEASON'] = sa_df['MONTH'].apply(get_season_australia)\n",
    "\n",
    "# Drop the intermediate 'MONTH' column if not needed\n",
    "# sa_df.drop(columns=['MONTH'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1460412-3e42-4e3b-b6b5-fd3b0e7ca346",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract weekday from DATETIME column\n",
    "sa_df['WEEKDAY'] = sa_df['DATETIME'].dt.weekday\n",
    "\n",
    "# Print out a few rows to verify\n",
    "print(sa_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486b27d0-54ff-4a47-920c-1f8f8038b5d2",
   "metadata": {},
   "source": [
    "# Power Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25470f94-afdc-40d0-ac9a-3ca67e2edf02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316ae742-010c-4273-9b21-1140f0049dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38601733-4f18-421f-b997-53e45a1d995d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Load power prices data from CSV file\n",
    "# # Replace 'power_prices.csv' with the actual file path\n",
    "# power_prices_df = pd.read_csv('power_prices.csv')\n",
    "\n",
    "# # Assuming the DataFrame has columns 'Date' and 'Price', and 'Date' is in datetime format\n",
    "# # If 'Date' is not in datetime format, you can convert it using pd.to_datetime()\n",
    "\n",
    "# # Filter data for the periods 2017 to 2021\n",
    "# start_date = '2017-01-01'\n",
    "# end_date = '2021-12-31'\n",
    "\n",
    "# power_prices_filtered_df = power_prices_df[(power_prices_df['Date'] >= start_date) & (power_prices_df['Date'] <= end_date)]\n",
    "\n",
    "# # Display the first few rows of the filtered DataFrame\n",
    "# print(power_prices_filtered_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea46f02-554f-42d7-93a4-f97d3c5adb73",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Add in holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2c18eb-9e12-46dc-a758-16f13eea05fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9034424-81f4-4eb2-85e9-83040a2caf48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract unique years from DATETIME column\n",
    "years = sa_df['DATETIME'].dt.year.unique()\n",
    "\n",
    "# Print out the years\n",
    "print(\"Years contained in sa_df:\", years)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737537ae-e4cd-4246-baac-050169c41b96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c8c763-7ac6-4f92-84cb-8b4a7c72e40e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import holidays\n",
    "\n",
    "# Generate Australian public holidays for a specific year\n",
    "year = years  # Specify the year for which you want to generate public holidays\n",
    "australian_holidays = holidays.AU(years=year)\n",
    "\n",
    "# Convert the holidays to a DataFrame\n",
    "holiday_dates = [(date, name) for date, name in australian_holidays.items()]\n",
    "australian_public_holidays = pd.DataFrame(holiday_dates, columns=['Date', 'Holiday'])\n",
    "\n",
    "# Print out the DataFrame\n",
    "print(australian_public_holidays)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9121c83-1caf-4e3b-99d3-fcae6d0d0655",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convert 'Date' column to datetime type in australian_public_holidays DataFrame\n",
    "australian_public_holidays['Date'] = pd.to_datetime(australian_public_holidays['Date'])\n",
    "\n",
    "# Merge sa_df with australian_public_holidays based on the date\n",
    "sa_df = pd.merge(sa_df, australian_public_holidays, left_on='DATETIME', right_on='Date', how='left')\n",
    "\n",
    "# Create a new column indicating whether each date is a public holiday or not\n",
    "sa_df['IS_PUBLIC_HOLIDAY'] = sa_df['Holiday'].notnull().astype(int)\n",
    "\n",
    "# Drop the intermediate 'Date' and 'Holiday' columns if not needed\n",
    "sa_df.drop(columns=['Date', 'Holiday'], inplace=True)\n",
    "\n",
    "# Print out a few rows to verify\n",
    "print(sa_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073f6ed1-27bb-4db7-abef-08b3ab72ae50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Report column types\n",
    "column_types = sa_df.dtypes\n",
    "\n",
    "# Print out the column types\n",
    "print(\"Column types in sa_df:\")\n",
    "print(column_types)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def312ba-8a14-474e-9747-9c459dc9dfc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7baea3-826d-441e-90b3-5c3edd2f2e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Cooling and Heating values for sa_df\n",
    "sa_df['Cooling'] = sa_df['TEMPERATURE'].apply(lambda x: max(0, x - 24))\n",
    "sa_df['Heating'] = sa_df['TEMPERATURE'].apply(lambda x: max(0, 20 - x))\n",
    "\n",
    "# Print out a few rows to verify\n",
    "print(sa_df[['Cooling', 'Heating']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a96025-d4c3-44c9-b6cf-f74b77be6ff3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add a new column with an increasing index starting from 1\n",
    "sa_df['INDEX'] = (sa_df['TEMPERATURE'].notnull()).cumsum().shift(fill_value=0) + 1\n",
    "\n",
    "# Print out a few rows to verify\n",
    "print(sa_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaba7d11-37c7-41a9-b511-042555da3eb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Define categorical, numerical, and binary features\n",
    "categorical_features = ['WEEKDAY']\n",
    "numerical_features = ['YEAR', 'MONTH', 'DAY', 'HOUR', 'TEMPERATURE']\n",
    "binary_features = ['IS_PUBLIC_HOLIDAY', 'Cooling', 'Heating']\n",
    "\n",
    "# Split features and target\n",
    "X = sa_df[categorical_features + numerical_features + binary_features]\n",
    "y = sa_df['TOTALDEMAND']\n",
    "\n",
    "# Define preprocessing steps for different types of features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),  # Standardize numerical features\n",
    "        ('cat', OneHotEncoder(), categorical_features),  # One-hot encode categorical features\n",
    "        ('bin', 'passthrough', binary_features)  # Include binary features as is\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with preprocessing and linear regression model\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Split dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the pipeline (preprocessing + linear regression model) on training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Test MSE:\", mse)\n",
    "\n",
    "# Calculate R-squared\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R^2 Score:\", r2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617aaf25-0203-4324-95f3-6665792b17e7",
   "metadata": {},
   "source": [
    "Check Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e3db29-0919-46df-adfc-389d20c92efa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = list(preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features)) + \\\n",
    "                numerical_features + binary_features\n",
    "\n",
    "# Get coefficients of the linear regression model\n",
    "coefficients = pipeline.named_steps['regressor'].coef_\n",
    "\n",
    "# Create a DataFrame to display feature importance\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefficients})\n",
    "feature_importance_df['Absolute Coefficient'] = feature_importance_df['Coefficient'].abs()  # Absolute values\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Absolute Coefficient', ascending=False)\n",
    "\n",
    "# Display feature importance\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f61b137-750e-4180-8006-a315d079b2bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a mapping of seasons to integers\n",
    "season_mapping = {'Spring': 0, 'Summer': 1, 'Autumn': 2, 'Winter': 3}\n",
    "\n",
    "# Map seasons to integers\n",
    "sa_df['SEASON_INT'] = sa_df['SEASON'].map(season_mapping)\n",
    "\n",
    "# Print out a few rows to verify\n",
    "print(sa_df[['SEASON', 'SEASON_INT']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d980f5-1ef6-46a7-b9fa-c77b2538ebb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "column_types = sa_df.dtypes\n",
    "\n",
    "# Print out the column types\n",
    "print(\"Column types in sa_df:\")\n",
    "print(column_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b66a8d-8659-4bc0-a9ff-483d259d6609",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510e2579-8798-4252-8152-1fc9d423feff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split dataset into train, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Define the neural network model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Define early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model with validation data\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_validation, y_validation), callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "mse = model.evaluate(X_test, y_test)\n",
    "print(\"Test MSE:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5345a8-6824-4a20-8152-7f36a1af202a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In this attempt, i used Index (a number increasing from 0 upwards for each record - no date / time).\n",
    "# it shows that specific times are important drivers with the low acccuracy generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5938097-262f-482c-8bbd-73c90b399292",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# # Extract relevant features from DATETIME column\n",
    "# sa_df['YEAR'] = sa_df['DATETIME'].dt.year\n",
    "# sa_df['MONTH'] = sa_df['DATETIME'].dt.month\n",
    "# sa_df['DAY'] = sa_df['DATETIME'].dt.day\n",
    "# sa_df['HOUR'] = sa_df['DATETIME'].dt.hour\n",
    "\n",
    "# Select features and target\n",
    "X = sa_df[['INDEX', 'TEMPERATURE', 'IS_PUBLIC_HOLIDAY', 'Cooling', 'Heating', 'WEEKDAY']].values\n",
    "y = sa_df['TOTALDEMAND'].values\n",
    "\n",
    "# Normalize features\n",
    "scaler_X = MinMaxScaler(feature_range=(0, 1))\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "# Normalize target\n",
    "scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
    "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Define function to create time series dataset\n",
    "def create_dataset(X, y, time_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:(i + time_steps)])\n",
    "        ys.append(y[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "# Define time steps\n",
    "TIME_STEPS = 7\n",
    "\n",
    "# Create time series dataset\n",
    "X_ts, y_ts = create_dataset(X_scaled, y_scaled, TIME_STEPS)\n",
    "\n",
    "# Split dataset into train and test sets\n",
    "split = int(0.8 * len(X_ts))\n",
    "X_train, X_test = X_ts[:split], X_ts[split:]\n",
    "y_train, y_test = y_ts[:split], y_ts[split:]\n",
    "\n",
    "# Define LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(units=50, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dense(units=1)\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Define early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate model\n",
    "mse = model.evaluate(X_test, y_test)\n",
    "print(\"Test MSE:\", mse)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_scaled = model.predict(X_test)\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_scaled))\n",
    "print(\"Test RMSE:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007402ee-4201-491d-8857-634eaf2bbd92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Compute MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Test MSE:\", mse)\n",
    "\n",
    "# Compute RMSE\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "\n",
    "# Compute MAE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Test MAE:\", mae)\n",
    "\n",
    "# Compute R^2\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R^2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab282d9-f35d-47a1-96db-ab3fb1a85d29",
   "metadata": {},
   "source": [
    "# Report the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfe3652-b132-4dc7-a5fc-e1028fcc3529",
   "metadata": {
    "tags": []
   },
   "source": [
    "# plotting the results shows a poor estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dd38af-7bdd-472e-8912-380f60b109a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform the scaled predicted and actual values to their original scale\n",
    "y_pred_actual = scaler_y.inverse_transform(y_pred)\n",
    "y_test_actual = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "# Get the total number of periods in the dataset\n",
    "total_periods = len(y_test_actual)\n",
    "\n",
    "# Randomly select 50 periods\n",
    "random_indices = np.random.choice(total_periods, size=50, replace=False)\n",
    "\n",
    "# Extract the actual and predicted values for the randomly selected periods\n",
    "random_actual = y_test_actual[random_indices]\n",
    "random_predicted = y_pred_actual[random_indices]\n",
    "\n",
    "# Plot actual vs predicted values for the randomly selected periods\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(random_actual, label='Actual', marker='o', linestyle='-')\n",
    "plt.plot(random_predicted, label='Predicted', marker='o', linestyle='-')\n",
    "plt.title('Actual vs Predicted TOTALDEMAND for Randomly Selected Periods')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('TOTALDEMAND')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d758ba25-8b8a-4d9f-ba90-6909b8b6d1fb",
   "metadata": {},
   "source": [
    "#Choosing a random sample of 50 points to plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd90100-1833-427c-bb5c-c3d2db616bf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform the scaled predicted and actual values to their original scale\n",
    "y_pred_actual = scaler_y.inverse_transform(y_pred)\n",
    "y_test_actual = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "# Get the total number of periods in the dataset\n",
    "total_periods = len(y_test_actual)\n",
    "\n",
    "# Randomly select 50 periods\n",
    "random_indices = np.random.choice(total_periods, size=50, replace=False)\n",
    "\n",
    "# Extract the actual and predicted values for the randomly selected periods\n",
    "random_actual = y_test_actual[random_indices]\n",
    "random_predicted = y_pred_actual[random_indices]\n",
    "\n",
    "# Plot actual vs predicted values for the randomly selected periods\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(random_actual, label='Actual', marker='o', linestyle='-')\n",
    "plt.plot(random_predicted, label='Predicted', marker='o', linestyle='-')\n",
    "plt.title('Actual vs Predicted TOTALDEMAND for Randomly Selected Periods')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('TOTALDEMAND')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3a140c-13ae-43b2-b70e-55b564cba2ad",
   "metadata": {},
   "source": [
    "# Trying again with year, month, day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5000336e-06d5-486b-9aaf-977d76b93081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Select features and target\n",
    "X = sa_df[['YEAR', 'MONTH', 'DAY', 'HOUR', 'TEMPERATURE', 'IS_PUBLIC_HOLIDAY', 'Cooling', 'Heating', 'WEEKDAY']].values\n",
    "y = sa_df['TOTALDEMAND'].values\n",
    "\n",
    "# Normalize features\n",
    "scaler_X = MinMaxScaler(feature_range=(0, 1))\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "# Normalize target\n",
    "scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
    "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Split dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the neural network model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Define early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "mse = model.evaluate(X_test, y_test)\n",
    "print(\"Test MSE:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23c3f76-68c3-4b8c-bc81-3563c6cc6326",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Select features and target\n",
    "X = sa_df[['YEAR', 'MONTH', 'DAY', 'HOUR', 'TEMPERATURE', 'IS_PUBLIC_HOLIDAY', 'Cooling', 'Heating', 'WEEKDAY']].values\n",
    "y = sa_df['TOTALDEMAND'].values\n",
    "\n",
    "# Normalize features\n",
    "scaler_X = MinMaxScaler(feature_range=(0, 1))\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "# Normalize target\n",
    "scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
    "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Split dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape input data for LSTM model (samples, time steps, features)\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(units=50, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dense(units=1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Define early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "mse = model.evaluate(X_test, y_test)\n",
    "print(\"Test MSE:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390f75f7-a896-4c7f-8164-2b6a88dcd857",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Compute MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Test MSE:\", mse)\n",
    "\n",
    "# Compute RMSE\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "\n",
    "# Compute MAE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Test MAE:\", mae)\n",
    "\n",
    "# Compute R^2\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R^2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fcbc6e-7d94-4033-94a3-3a2dd22cc522",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform the scaled predicted and actual values to their original scale\n",
    "y_pred_actual = scaler_y.inverse_transform(y_pred)\n",
    "y_test_actual = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "# Extract the first 100 actual and predicted values\n",
    "first_50_actual = y_test_actual[:50]\n",
    "first_50_predicted = y_pred_actual[:50]\n",
    "\n",
    "# Plot actual vs predicted values for the first 50 values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(first_50_actual, label='Actual', marker='o', linestyle='-')\n",
    "plt.plot(first_50_predicted, label='Predicted', marker='o', linestyle='-')\n",
    "plt.title('Actual vs Predicted TOTALDEMAND for the First 50 Values')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('TOTALDEMAND')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7c46da-72b6-4d94-9e58-15685e8b9024",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Note above model is struggling to predict the outlier peaks and troughs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88feb60-1483-4d82-b1a6-57bf6e3f6f01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_months = np.unique(X_test[:, :, 1])\n",
    "print(\"Unique months in the test dataset:\", unique_months)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c9dca9-c436-4391-b6f1-718df023094b",
   "metadata": {},
   "source": [
    "# Randomly Select 50 Periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bda8ad7-b7f0-45d0-83aa-a71d714261e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform the scaled predicted and actual values to their original scale\n",
    "y_pred_actual = scaler_y.inverse_transform(y_pred)\n",
    "y_test_actual = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "# Get the total number of periods in the dataset\n",
    "total_periods = len(y_test_actual)\n",
    "\n",
    "# Randomly select 50 periods\n",
    "random_indices = np.random.choice(total_periods, size=50, replace=False)\n",
    "\n",
    "# Extract the actual and predicted values for the randomly selected periods\n",
    "random_actual = y_test_actual[random_indices]\n",
    "random_predicted = y_pred_actual[random_indices]\n",
    "\n",
    "# Plot actual vs predicted values for the randomly selected periods\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(random_actual, label='Actual', marker='o', linestyle='-')\n",
    "plt.plot(random_predicted, label='Predicted', marker='o', linestyle='-')\n",
    "plt.title('Actual vs Predicted TOTALDEMAND for Randomly Selected Periods')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('TOTALDEMAND')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8c3082-99d8-47b0-bb5f-c62fdb04de28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
